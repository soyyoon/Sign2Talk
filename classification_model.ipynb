{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMjTf3jeP1t5JQrgVoHJaHX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soyyoon/Sign2Talk/blob/main/classification_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fd2PfhK3oH3L"
      },
      "outputs": [],
      "source": [
        "!pip install -q scikit-learn seaborn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, callbacks\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "from scipy.ndimage import gaussian_filter1d\n",
        "import xgboost as xgb\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Seed\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "DATA_DIR = '/content/drive/MyDrive/S2T/features_basic_47dim'\n",
        "MAX_FRAMES = 30\n",
        "FEATURE_DIM = 47\n",
        "VAL_SPLIT_SIZE = 0.2\n",
        "BATCH_SIZE = 32"
      ],
      "metadata": {
        "id": "GNvjSIckosBr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06ff0ed8-6962-44e1-fff3-ae8d0a4ce2bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. ë°ì´í„° ë¡œë”© ë° TF Dataset í—¬í¼"
      ],
      "metadata": {
        "id": "89hdjZFQ8a7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_all_data(data_dir, max_frames=30, feature_dim=47):\n",
        "    \"\"\"NPY íŒŒì¼ ë¡œë“œ\"\"\"\n",
        "    print(\"=\"*60)\n",
        "    print(\"ğŸ“¦ ë°ì´í„° ë¡œë”©\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    X_data = []\n",
        "    y_data = []\n",
        "\n",
        "    class_names = sorted([d for d in os.listdir(data_dir)\n",
        "                          if os.path.isdir(os.path.join(data_dir, d))\n",
        "                          and not d.startswith('.')])\n",
        "\n",
        "    print(f\"ğŸ“‚ í´ë˜ìŠ¤: {len(class_names)}ê°œ\")\n",
        "\n",
        "    for class_idx, class_name in enumerate(tqdm(class_names, desc=\"Loading\")):\n",
        "        class_path = os.path.join(data_dir, class_name)\n",
        "        npy_files = glob.glob(os.path.join(class_path, \"*.npy\"))\n",
        "\n",
        "        for fpath in npy_files:\n",
        "            try:\n",
        "                arr = np.load(fpath)\n",
        "                if arr.shape == (max_frames, feature_dim):\n",
        "                    X_data.append(arr)\n",
        "                    y_data.append(class_idx)\n",
        "            except Exception as e:\n",
        "                print(f\"Warning: Skipping file {fpath} due to error: {e}\")\n",
        "                continue\n",
        "\n",
        "    X_data = np.array(X_data, dtype=np.float32)\n",
        "    y_data = np.array(y_data, dtype=np.int32)\n",
        "\n",
        "    print(f\"\\nâœ… ì´ ìƒ˜í”Œ: {len(X_data)}ê°œ\")\n",
        "    return X_data, y_data, class_names\n",
        "\n",
        "\n",
        "def create_augmented_dataset(X, y, batch_size=32, augment_fn=None):\n",
        "    \"\"\"\n",
        "    Numpy ë°°ì—´ê³¼ ì¦ê°• í•¨ìˆ˜ë¥¼ ë°›ì•„ tf.data.Dataset ìƒì„±\n",
        "    \"\"\"\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((X, y))\n",
        "    dataset = dataset.shuffle(len(X), seed=SEED)\n",
        "\n",
        "    if augment_fn:\n",
        "        def tf_augment_fn(x, y):\n",
        "            # tf.py_functionì„ ì‚¬ìš©í•˜ì—¬ Numpy ê¸°ë°˜ ì¦ê°• í•¨ìˆ˜ ë˜í•‘\n",
        "            [x_aug] = tf.py_function(\n",
        "                func=lambda b: [augment_fn(b.numpy()[np.newaxis, ...])[0]],\n",
        "                inp=[x],\n",
        "                Tout=[tf.float32]\n",
        "            )\n",
        "            x_aug.set_shape((MAX_FRAMES, FEATURE_DIM))\n",
        "            return x_aug, y\n",
        "\n",
        "        # ì¦ê°• ì ìš©\n",
        "        dataset = dataset.map(tf_augment_fn, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "PTDVhDqw71B6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ì†ì‹¤ í•¨ìˆ˜ (Label Smoothing)"
      ],
      "metadata": {
        "id": "Gw2aOoxa8jkM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def smooth_sparse_categorical_crossentropy(y_true, y_pred, label_smoothing=0.1):\n",
        "    num_classes = tf.shape(y_pred)[-1]\n",
        "    y_true = tf.cast(y_true, tf.int32)\n",
        "    y_true_one_hot = tf.one_hot(y_true, depth=num_classes)\n",
        "\n",
        "    y_true_smoothed = y_true_one_hot * (1 - label_smoothing) + \\\n",
        "                      (label_smoothing / tf.cast(num_classes, tf.float32))\n",
        "\n",
        "    loss = -tf.reduce_sum(\n",
        "        y_true_smoothed * tf.math.log(tf.clip_by_value(y_pred, 1e-7, 1.0)),\n",
        "        axis=-1\n",
        "    )\n",
        "    return tf.reduce_mean(loss)"
      ],
      "metadata": {
        "id": "kal9j7Ew8ii6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. ëª¨ë¸ ì•„í‚¤í…ì³"
      ],
      "metadata": {
        "id": "iVA7uxMY8qLD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_cnn_attention_deep(input_shape, num_classes):\n",
        "    \"\"\"ë” ê¹Šì€ CNN + Attention\"\"\"\n",
        "    inp = layers.Input(shape=input_shape)\n",
        "    x = layers.Conv1D(128, 3, padding=\"same\")(inp)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "    x = layers.Conv1D(128, 3, padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "    x = layers.Conv1D(256, 3, padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "    x = layers.Conv1D(256, 3, padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "    attn_scores = layers.Dense(1)(x)\n",
        "    attn_scores = layers.Softmax(axis=1)(attn_scores)\n",
        "    def weighted_sum(args):\n",
        "        feats, scores = args\n",
        "        return tf.reduce_sum(feats * scores, axis=1)\n",
        "    x = layers.Lambda(weighted_sum)([x, attn_scores])\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    x = layers.Dense(256, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(0.4)(x)\n",
        "    x = layers.Dense(128, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    out = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "    return models.Model(inp, out)\n",
        "\n",
        "\n",
        "def build_bilstm_attention(input_shape, num_classes):\n",
        "    \"\"\"BiLSTM + Multi-head Attention\"\"\"\n",
        "    inp = layers.Input(shape=input_shape)\n",
        "    x = layers.Conv1D(128, 3, padding=\"same\")(inp)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.Bidirectional(layers.LSTM(128, return_sequences=True))(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    attn_output = layers.MultiHeadAttention(\n",
        "        num_heads=4, key_dim=64, dropout=0.2\n",
        "    )(x, x)\n",
        "    x = layers.LayerNormalization()(x + attn_output)\n",
        "    avg_pool = layers.GlobalAveragePooling1D()(x)\n",
        "    max_pool = layers.GlobalMaxPooling1D()(x)\n",
        "    x = layers.Concatenate()([avg_pool, max_pool])\n",
        "    x = layers.Dense(256, activation='relu')(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    x = layers.Dense(128, activation='relu')(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    out = layers.Dense(num_classes, activation='softmax')(x)\n",
        "    return models.Model(inp, out)\n",
        "\n",
        "\n",
        "def build_transformer_model(input_shape, num_classes):\n",
        "    \"\"\"Transformer Encoder\"\"\"\n",
        "    inp = layers.Input(shape=input_shape)\n",
        "    x = layers.Dense(128)(inp)\n",
        "    x = layers.LayerNormalization()(x)\n",
        "    positions = tf.range(start=0, limit=input_shape[0], delta=1)\n",
        "    position_embedding = layers.Embedding(\n",
        "        input_dim=input_shape[0], output_dim=128\n",
        "    )(positions)\n",
        "    x = x + position_embedding\n",
        "    for _ in range(3):\n",
        "        attn_output = layers.MultiHeadAttention(\n",
        "            num_heads=4, key_dim=32, dropout=0.2\n",
        "        )(x, x)\n",
        "        x = layers.LayerNormalization()(x + attn_output)\n",
        "        ffn = tf.keras.Sequential([\n",
        "            layers.Dense(256, activation=\"relu\"),\n",
        "            layers.Dropout(0.2),\n",
        "            layers.Dense(128),\n",
        "        ])\n",
        "        ffn_output = ffn(x)\n",
        "        x = layers.LayerNormalization()(x + ffn_output)\n",
        "    x = layers.GlobalAveragePooling1D()(x)\n",
        "    x = layers.Dense(128, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(0.4)(x)\n",
        "    out = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "    return models.Model(inp, out)\n",
        "\n",
        "\n",
        "def build_resnet_1d(input_shape, num_classes):\n",
        "    \"\"\"1D ResNet\"\"\"\n",
        "    inp = layers.Input(shape=input_shape)\n",
        "    def residual_block(x, filters, kernel_size=3):\n",
        "        shortcut = x\n",
        "        x = layers.Conv1D(filters, kernel_size, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.Activation('relu')(x)\n",
        "        x = layers.Dropout(0.2)(x)\n",
        "        x = layers.Conv1D(filters, kernel_size, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        if shortcut.shape[-1] != filters:\n",
        "            shortcut = layers.Conv1D(filters, 1, padding=\"same\")(shortcut)\n",
        "        x = layers.Add()([x, shortcut])\n",
        "        x = layers.Activation('relu')(x)\n",
        "        return x\n",
        "    x = layers.Conv1D(64, 7, padding=\"same\")(inp)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = residual_block(x, 64)\n",
        "    x = residual_block(x, 128)\n",
        "    x = residual_block(x, 256)\n",
        "    x = layers.GlobalAveragePooling1D()(x)\n",
        "    x = layers.Dense(128, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    out = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "    return models.Model(inp, out)"
      ],
      "metadata": {
        "id": "SRYUgG7N8owh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. ë°ì´í„° ì¦ê°•"
      ],
      "metadata": {
        "id": "p7rXOSWo8w1P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mega_augment_batch(batch):\n",
        "    \"\"\"ìµœê°• ì¦ê°• (ë°°ì¹˜ ë‹¨ìœ„ê°€ ì•„ë‹Œ ë‹¨ì¼ ìƒ˜í”Œ [1, T, F] ëŒ€ìƒ)\"\"\"\n",
        "    # ì…ë ¥ì´ (1, T, F)ì´ë¯€ë¡œ [0]ì„ í†µí•´ (T, F)ë¡œ ì‘ì—…\n",
        "    augmented = batch[0].copy()\n",
        "\n",
        "    if np.random.rand() < 0.8:\n",
        "        noise_level = np.random.uniform(0.01, 0.02)\n",
        "        noise = np.random.normal(0, noise_level, size=augmented.shape)\n",
        "        augmented = augmented + noise\n",
        "    if np.random.rand() < 0.6:\n",
        "        shift = np.random.choice([-3, -2, -1, 1, 2, 3])\n",
        "        augmented = np.roll(augmented, shift, axis=0) # axis=0 (ì‹œê°„)\n",
        "    if np.random.rand() < 0.5:\n",
        "        scale = np.random.uniform(0.85, 1.15)\n",
        "        augmented = augmented * scale\n",
        "    if np.random.rand() < 0.4:\n",
        "        mask_len = np.random.randint(1, 5)\n",
        "        mask_start = np.random.randint(0, MAX_FRAMES - mask_len)\n",
        "        augmented[mask_start:mask_start+mask_len, :] = 0\n",
        "    if np.random.rand() < 0.4:\n",
        "        mask_features = np.random.randint(1, 8)\n",
        "        feature_indices = np.random.choice(FEATURE_DIM, mask_features, replace=False)\n",
        "        augmented[:, feature_indices] = 0\n",
        "    if np.random.rand() < 0.2:\n",
        "        augmented = augmented[::-1, :] # axis=0 (ì‹œê°„)\n",
        "    if np.random.rand() < 0.3:\n",
        "        sigma = np.random.uniform(0.5, 1.5)\n",
        "        augmented = gaussian_filter1d(augmented, sigma=sigma, axis=0) # axis=0 (ì‹œê°„)\n",
        "\n",
        "    # (T, F) -> (1, T, F)ë¡œ ë³µì›\n",
        "    return augmented.astype(np.float32)[np.newaxis, ...]"
      ],
      "metadata": {
        "id": "jfoa5fGq8vy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. í•˜ì´ë¸Œë¦¬ë“œ ì•™ìƒë¸” í•™ìŠµ"
      ],
      "metadata": {
        "id": "RP_xqJI983ro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_hybrid_ensemble(X_train_norm, X_val_norm, y_train, y_val,\n",
        "                          INPUT_SHAPE, NUM_CLASSES,\n",
        "                          train_ds, val_ds, class_weights):\n",
        "    \"\"\"ë‹¤ì–‘í•œ êµ¬ì¡°ì˜ ëª¨ë¸ì„ ì•™ìƒë¸” (ì •ê·œí™”ëœ ë°ì´í„° ì…ë ¥)\"\"\"\n",
        "\n",
        "    model_builders = [\n",
        "        ('CNN_Attention_v1', build_cnn_attention_deep, 0.001),\n",
        "        ('CNN_Attention_v2', build_cnn_attention_deep, 0.0005),\n",
        "        ('BiLSTM_Attention_v1', build_bilstm_attention, 0.001),\n",
        "        ('BiLSTM_Attention_v2', build_bilstm_attention, 0.0005),\n",
        "        ('Transformer_v1', build_transformer_model, 0.0008),\n",
        "        ('ResNet1D_v1', build_resnet_1d, 0.001),\n",
        "        ('ResNet1D_v2', build_resnet_1d, 0.0005),\n",
        "    ]\n",
        "\n",
        "    base_models = []\n",
        "    model_names = []\n",
        "\n",
        "    for name, builder, lr in model_builders:\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"ğŸ—ï¸ {name} í•™ìŠµ ì¤‘... (LR: {lr})\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        tf.random.set_seed(SEED + len(base_models)) # ëª¨ë¸ë³„ ì‹œë“œ ë³€ê²½\n",
        "        model = builder(INPUT_SHAPE, NUM_CLASSES)\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate=lr, clipnorm=1.0)\n",
        "\n",
        "        model.compile(\n",
        "            optimizer=optimizer,\n",
        "            loss=smooth_sparse_categorical_crossentropy,\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "\n",
        "        model.fit(\n",
        "            train_ds,\n",
        "            validation_data=val_ds,\n",
        "            epochs=100, # EarlyStoppingì´ ê´€ë¦¬\n",
        "            callbacks=[\n",
        "                callbacks.EarlyStopping(\n",
        "                    monitor='val_loss', patience=15, restore_best_weights=True, verbose=1\n",
        "                ),\n",
        "                callbacks.ReduceLROnPlateau(\n",
        "                    monitor='val_loss', factor=0.5, patience=5, min_lr=1e-7, verbose=1\n",
        "                )\n",
        "            ],\n",
        "            class_weight=class_weights,\n",
        "            verbose=1 # í•™ìŠµ ê³¼ì • ëª¨ë‹ˆí„°ë§\n",
        "        )\n",
        "\n",
        "        # ê²€ì¦ì…‹ í‰ê°€ (ì •ê·œí™”ëœ X_val_norm ì‚¬ìš©)\n",
        "        val_preds = model.predict(X_val_norm, batch_size=BATCH_SIZE, verbose=0)\n",
        "        val_acc = accuracy_score(y_val, np.argmax(val_preds, axis=1))\n",
        "        print(f\"  âœ… {name} Val Acc: {val_acc*100:.2f}%\")\n",
        "\n",
        "        base_models.append(model)\n",
        "        model_names.append(name)\n",
        "\n",
        "    return base_models, model_names"
      ],
      "metadata": {
        "id": "cvwXKrle80fc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. TTA"
      ],
      "metadata": {
        "id": "Q_9TeVi188iP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mega_tta_predict(models, X_val_norm, n_tta=20):\n",
        "    \"\"\"ê°•í™”ëœ TTA (ì •ê·œí™”ëœ ë°ì´í„° ì…ë ¥)\"\"\"\n",
        "    print(f\"\\nğŸ”® Mega TTA (ê° ëª¨ë¸ë‹¹ {n_tta}ë²ˆ ì¦ê°•)\")\n",
        "    all_predictions = []\n",
        "\n",
        "    for i, model in enumerate(tqdm(models, desc=\"TTA Models\")):\n",
        "        model_preds = []\n",
        "\n",
        "        # ì›ë³¸\n",
        "        preds = model.predict(X_val_norm, batch_size=BATCH_SIZE*2, verbose=0)\n",
        "        model_preds.append(preds)\n",
        "\n",
        "        # ì¦ê°• ë²„ì „ë“¤ (Numpy TTA)\n",
        "        for _ in range(n_tta - 1):\n",
        "            # TTAë¥¼ ìœ„í•´ ë°°ì¹˜ ì¦ê°•ì´ ì•„ë‹Œ ìƒ˜í”Œë³„ ì¦ê°• í•„ìš”\n",
        "            X_aug_list = []\n",
        "            for sample in X_val_norm:\n",
        "                aug_sample = mega_augment_batch(sample[np.newaxis, ...])[0]\n",
        "                X_aug_list.append(aug_sample)\n",
        "            X_aug = np.array(X_aug_list)\n",
        "\n",
        "            preds_aug = model.predict(X_aug, batch_size=BATCH_SIZE*2, verbose=0)\n",
        "            model_preds.append(preds_aug)\n",
        "\n",
        "        avg_preds = np.mean(model_preds, axis=0)\n",
        "        all_predictions.append(avg_preds)\n",
        "\n",
        "    final_preds = np.mean(all_predictions, axis=0)\n",
        "    return final_preds"
      ],
      "metadata": {
        "id": "rzGMhtTl87bG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. ìŠ¤íƒœí‚¹ ì•™ìƒë¸”"
      ],
      "metadata": {
        "id": "OP0KcLB69Ahk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def stacking_ensemble(models, X_train_norm, X_val_norm, y_train, y_val, NUM_CLASSES):\n",
        "    \"\"\"ìŠ¤íƒœí‚¹ ì•™ìƒë¸” (ë©”íƒ€ ëŸ¬ë„ˆ)\"\"\"\n",
        "    print(\"\\nğŸ¯ ìŠ¤íƒœí‚¹ ì•™ìƒë¸” í•™ìŠµ\")\n",
        "\n",
        "    train_meta_features = []\n",
        "    val_meta_features = []\n",
        "\n",
        "    for i, model in enumerate(tqdm(models, desc=\"Stacking Features\")):\n",
        "        train_preds = model.predict(X_train_norm, batch_size=BATCH_SIZE*2, verbose=0)\n",
        "        val_preds = model.predict(X_val_norm, batch_size=BATCH_SIZE*2, verbose=0)\n",
        "        train_meta_features.append(train_preds)\n",
        "        val_meta_features.append(val_preds)\n",
        "\n",
        "    X_train_meta = np.concatenate(train_meta_features, axis=1)\n",
        "    X_val_meta = np.concatenate(val_meta_features, axis=1)\n",
        "\n",
        "    print(f\"  ë©”íƒ€ íŠ¹ì§• shape: {X_train_meta.shape}\")\n",
        "\n",
        "    meta_model = tf.keras.Sequential([\n",
        "        layers.Input(shape=(X_train_meta.shape[1],)),\n",
        "        layers.Dense(256, activation='relu'),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(NUM_CLASSES, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    meta_model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "        loss='sparse_categorical_crossentropy', # ìŠ¤íƒœí‚¹ì€ ë ˆì´ë¸” ìŠ¤ë¬´ë”© ì—†ì´\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    meta_model.fit(\n",
        "        X_train_meta, y_train,\n",
        "        validation_data=(X_val_meta, y_val),\n",
        "        epochs=50,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        callbacks=[\n",
        "            callbacks.EarlyStopping(patience=10, restore_best_weights=True, verbose=0)\n",
        "        ],\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    stacked_preds = meta_model.predict(X_val_meta, verbose=0)\n",
        "    return stacked_preds, meta_model"
      ],
      "metadata": {
        "id": "Rc7Mdsp48_7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. ë©”ì¸ ì‹¤í–‰"
      ],
      "metadata": {
        "id": "Iu-I_vOS9Eqp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # 1. ë°ì´í„° ë¡œë“œ\n",
        "    X_data, y_data, class_names = load_all_data(DATA_DIR, MAX_FRAMES, FEATURE_DIM)\n",
        "    NUM_CLASSES = len(class_names)\n",
        "    INPUT_SHAPE = (MAX_FRAMES, FEATURE_DIM)\n",
        "\n",
        "    # 2. Train/Val ë¶„í•  (Data Leakage ë°©ì§€!)\n",
        "    print(\"\\nâœ‚ï¸ Train/Val ë¶„í• ...\")\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        X_data, y_data,\n",
        "        test_size=VAL_SPLIT_SIZE,\n",
        "        random_state=SEED,\n",
        "        stratify=y_data\n",
        "    )\n",
        "\n",
        "    # 3. ì •ê·œí™” (Train ê¸°ì¤€ìœ¼ë¡œ Val ì •ê·œí™”)\n",
        "    print(\"ğŸ”„ ë°ì´í„° ì •ê·œí™” (Standard Scaling)...\")\n",
        "    mean = X_train.mean(axis=(0, 1), keepdims=True)\n",
        "    std = X_train.std(axis=(0, 1), keepdims=True) + 1e-6\n",
        "\n",
        "    X_train_norm = (X_train - mean) / std\n",
        "    X_val_norm = (X_val - mean) / std\n",
        "\n",
        "    print(f\"  Train: {len(X_train_norm)}ê°œ, Val: {len(X_val_norm)}ê°œ\")\n",
        "\n",
        "    # 4. tf.data.Dataset ìƒì„±\n",
        "    # (ì£¼ì˜: train_dsëŠ” ì •ê·œí™”ë˜ì§€ *ì•Šì€* X_trainì„ ì‚¬ìš© -> ì¦ê°• í›„ ì •ê·œí™”)\n",
        "    # (ìˆ˜ì •: ì¦ê°•ë„ ì •ê·œí™”ëœ ë°ì´í„°ë¡œ í•˜ëŠ” ê²ƒì´ ì•ˆì •ì ì¼ ìˆ˜ ìˆìŒ. ì—¬ê¸°ì„œëŠ” í€¸ì˜ ì›ì•ˆëŒ€ë¡œ)\n",
        "    # (ìµœì¢… ìˆ˜ì •: ì •ê·œí™”ëœ ë°ì´í„°ë¡œ ì¦ê°•í•˜ëŠ” ê²ƒì´ ë§ìŒ!)\n",
        "\n",
        "    print(\"ğŸš€ tf.data íŒŒì´í”„ë¼ì¸ ìƒì„± (ì‹¤ì‹œê°„ ì¦ê°• í¬í•¨)...\")\n",
        "    train_ds = create_augmented_dataset(X_train_norm, y_train, BATCH_SIZE, mega_augment_batch)\n",
        "    val_ds = tf.data.Dataset.from_tensor_slices((X_val_norm, y_val)).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "    # 5. í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚°\n",
        "    print(\"âš–ï¸ í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚°...\")\n",
        "    class_weights = compute_class_weight(\n",
        "        class_weight=\"balanced\",\n",
        "        classes=np.unique(y_train),\n",
        "        y=y_train\n",
        "    )\n",
        "    class_weights_dict = {i: w for i, w in enumerate(class_weights)}\n",
        "\n",
        "    # 6. í•˜ì´ë¸Œë¦¬ë“œ ì•™ìƒë¸” í•™ìŠµ\n",
        "    base_models, model_names = train_hybrid_ensemble(\n",
        "        X_train_norm, X_val_norm, y_train, y_val,\n",
        "        INPUT_SHAPE, NUM_CLASSES,\n",
        "        train_ds, val_ds, class_weights_dict\n",
        "    )\n",
        "\n",
        "    # 7. ì•™ìƒë¸” ì„±ëŠ¥ í‰ê°€\n",
        "    print(\"\\n\\n\" + \"=\"*60)\n",
        "    print(\"ğŸ“Š ìµœì¢… ì„±ëŠ¥ í‰ê°€ (Validation Set)\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # ë°©ë²• 1: Averaging Ensemble\n",
        "    avg_preds_raw = np.mean([model.predict(X_val_norm, verbose=0) for model in base_models], axis=0)\n",
        "    avg_preds_labels = np.argmax(avg_preds_raw, axis=1)\n",
        "    avg_acc = accuracy_score(y_val, avg_preds_labels)\n",
        "    print(f\"ğŸ† [Averaging] Ensemble Accuracy: {avg_acc*100:.2f}%\")\n",
        "\n",
        "    # ë°©ë²• 2: Mega TTA\n",
        "    tta_preds_raw = mega_tta_predict(base_models, X_val_norm, n_tta=10) # ì‹œê°„ìƒ 10íšŒ\n",
        "    tta_preds_labels = np.argmax(tta_preds_raw, axis=1)\n",
        "    tta_acc = accuracy_score(y_val, tta_preds_labels)\n",
        "    print(f\"ğŸš€ [Mega TTA] Ensemble Accuracy : {tta_acc*100:.2f}%\")\n",
        "\n",
        "    # ë°©ë²• 3: Stacking Ensemble\n",
        "    stacked_preds_raw, meta_model = stacking_ensemble(\n",
        "        base_models, X_train_norm, X_val_norm, y_train, y_val, NUM_CLASSES\n",
        "    )\n",
        "    stacked_preds_labels = np.argmax(stacked_preds_raw, axis=1)\n",
        "    stacking_acc = accuracy_score(y_val, stacked_preds_labels)\n",
        "    print(f\"ğŸ‘‘ [Stacking] Ensemble Accuracy: {stacking_acc*100:.2f}%\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"ğŸ‰ ëª¨ë“  í•™ìŠµ ë° í‰ê°€ ì™„ë£Œ.\")\n",
        "    print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4w1vYKa9EED",
        "outputId": "8d2684d9-f121-4ac5-cc28-f2e2d902f390"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "ğŸ“¦ ë°ì´í„° ë¡œë”©\n",
            "============================================================\n",
            "ğŸ“‚ í´ë˜ìŠ¤: 67ê°œ\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [16:34<00:00, 14.85s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… ì´ ìƒ˜í”Œ: 1229ê°œ\n",
            "\n",
            "âœ‚ï¸ Train/Val ë¶„í• ...\n",
            "ğŸ”„ ë°ì´í„° ì •ê·œí™” (Standard Scaling)...\n",
            "  Train: 983ê°œ, Val: 246ê°œ\n",
            "ğŸš€ tf.data íŒŒì´í”„ë¼ì¸ ìƒì„± (ì‹¤ì‹œê°„ ì¦ê°• í¬í•¨)...\n",
            "âš–ï¸ í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚°...\n",
            "\n",
            "============================================================\n",
            "ğŸ—ï¸ CNN_Attention_v1 í•™ìŠµ ì¤‘... (LR: 0.001)\n",
            "============================================================\n",
            "Epoch 1/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 385ms/step - accuracy: 0.0122 - loss: 4.3078 - val_accuracy: 0.0203 - val_loss: 4.1999 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.0378 - loss: 4.2043 - val_accuracy: 0.0203 - val_loss: 4.1661 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.0232 - loss: 4.1469 - val_accuracy: 0.0528 - val_loss: 4.0065 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.0515 - loss: 4.0364 - val_accuracy: 0.0528 - val_loss: 3.9592 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.0474 - loss: 3.9255 - val_accuracy: 0.0976 - val_loss: 3.6801 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.0786 - loss: 3.7469 - val_accuracy: 0.1545 - val_loss: 3.5564 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.0670 - loss: 3.6868 - val_accuracy: 0.1341 - val_loss: 3.3180 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.1287 - loss: 3.5028 - val_accuracy: 0.2561 - val_loss: 3.1241 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.1479 - loss: 3.4212 - val_accuracy: 0.2236 - val_loss: 3.1038 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.1412 - loss: 3.3942 - val_accuracy: 0.2846 - val_loss: 2.9501 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.1700 - loss: 3.2468 - val_accuracy: 0.2724 - val_loss: 2.9176 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.1945 - loss: 3.2283 - val_accuracy: 0.2561 - val_loss: 2.9263 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.1900 - loss: 3.1611 - val_accuracy: 0.2846 - val_loss: 2.7786 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.2116 - loss: 3.0943 - val_accuracy: 0.3659 - val_loss: 2.6379 - learning_rate: 0.0010\n",
            "Epoch 15/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.1916 - loss: 3.0041 - val_accuracy: 0.3902 - val_loss: 2.6061 - learning_rate: 0.0010\n",
            "Epoch 16/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.2479 - loss: 2.9403 - val_accuracy: 0.3333 - val_loss: 2.5542 - learning_rate: 0.0010\n",
            "Epoch 17/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.2508 - loss: 2.8890 - val_accuracy: 0.4309 - val_loss: 2.4474 - learning_rate: 0.0010\n",
            "Epoch 18/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.2296 - loss: 2.9188 - val_accuracy: 0.4309 - val_loss: 2.4288 - learning_rate: 0.0010\n",
            "Epoch 19/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.2753 - loss: 2.7798 - val_accuracy: 0.4634 - val_loss: 2.3254 - learning_rate: 0.0010\n",
            "Epoch 20/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.2981 - loss: 2.7883 - val_accuracy: 0.4634 - val_loss: 2.3292 - learning_rate: 0.0010\n",
            "Epoch 21/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.3618 - loss: 2.6357 - val_accuracy: 0.4959 - val_loss: 2.2633 - learning_rate: 0.0010\n",
            "Epoch 22/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.3431 - loss: 2.6773 - val_accuracy: 0.5081 - val_loss: 2.2098 - learning_rate: 0.0010\n",
            "Epoch 23/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.3493 - loss: 2.6173 - val_accuracy: 0.5488 - val_loss: 2.1510 - learning_rate: 0.0010\n",
            "Epoch 24/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.3861 - loss: 2.5264 - val_accuracy: 0.4715 - val_loss: 2.2365 - learning_rate: 0.0010\n",
            "Epoch 25/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.3823 - loss: 2.5353 - val_accuracy: 0.5325 - val_loss: 2.1936 - learning_rate: 0.0010\n",
            "Epoch 26/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.3641 - loss: 2.5515 - val_accuracy: 0.5041 - val_loss: 2.1202 - learning_rate: 0.0010\n",
            "Epoch 27/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.4096 - loss: 2.5420 - val_accuracy: 0.5569 - val_loss: 2.1074 - learning_rate: 0.0010\n",
            "Epoch 28/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.3974 - loss: 2.4915 - val_accuracy: 0.5325 - val_loss: 2.0847 - learning_rate: 0.0010\n",
            "Epoch 29/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.4534 - loss: 2.3862 - val_accuracy: 0.5569 - val_loss: 2.0583 - learning_rate: 0.0010\n",
            "Epoch 30/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.4503 - loss: 2.3625 - val_accuracy: 0.4919 - val_loss: 2.1344 - learning_rate: 0.0010\n",
            "Epoch 31/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.4223 - loss: 2.4771 - val_accuracy: 0.5610 - val_loss: 2.0611 - learning_rate: 0.0010\n",
            "Epoch 32/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.4466 - loss: 2.3350 - val_accuracy: 0.5650 - val_loss: 2.0234 - learning_rate: 0.0010\n",
            "Epoch 33/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.4369 - loss: 2.3638 - val_accuracy: 0.5976 - val_loss: 1.9876 - learning_rate: 0.0010\n",
            "Epoch 34/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.4896 - loss: 2.2101 - val_accuracy: 0.5854 - val_loss: 1.9108 - learning_rate: 0.0010\n",
            "Epoch 35/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.4880 - loss: 2.2654 - val_accuracy: 0.5976 - val_loss: 1.9109 - learning_rate: 0.0010\n",
            "Epoch 36/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.5227 - loss: 2.1927 - val_accuracy: 0.5732 - val_loss: 1.9149 - learning_rate: 0.0010\n",
            "Epoch 37/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.5165 - loss: 2.1733 - val_accuracy: 0.6016 - val_loss: 1.9125 - learning_rate: 0.0010\n",
            "Epoch 38/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.4921 - loss: 2.2558 - val_accuracy: 0.6138 - val_loss: 1.9080 - learning_rate: 0.0010\n",
            "Epoch 39/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.4811 - loss: 2.2511 - val_accuracy: 0.6138 - val_loss: 1.8733 - learning_rate: 0.0010\n",
            "Epoch 40/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.5467 - loss: 2.0942 - val_accuracy: 0.6260 - val_loss: 1.8686 - learning_rate: 0.0010\n",
            "Epoch 41/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.5509 - loss: 2.1174 - val_accuracy: 0.6626 - val_loss: 1.8347 - learning_rate: 0.0010\n",
            "Epoch 42/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.5338 - loss: 2.1244 - val_accuracy: 0.6098 - val_loss: 1.8785 - learning_rate: 0.0010\n",
            "Epoch 43/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.5458 - loss: 2.1409 - val_accuracy: 0.6057 - val_loss: 1.8700 - learning_rate: 0.0010\n",
            "Epoch 44/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.5506 - loss: 2.0875 - val_accuracy: 0.6341 - val_loss: 1.8101 - learning_rate: 0.0010\n",
            "Epoch 45/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.5703 - loss: 2.0239 - val_accuracy: 0.6341 - val_loss: 1.8024 - learning_rate: 0.0010\n",
            "Epoch 46/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.5672 - loss: 2.0738 - val_accuracy: 0.6585 - val_loss: 1.8108 - learning_rate: 0.0010\n",
            "Epoch 47/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.5888 - loss: 2.0377 - val_accuracy: 0.6260 - val_loss: 1.7931 - learning_rate: 0.0010\n",
            "Epoch 48/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.5886 - loss: 1.9890 - val_accuracy: 0.6220 - val_loss: 1.8269 - learning_rate: 0.0010\n",
            "Epoch 49/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.5893 - loss: 2.0370 - val_accuracy: 0.6667 - val_loss: 1.7287 - learning_rate: 0.0010\n",
            "Epoch 50/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.6045 - loss: 1.9910 - val_accuracy: 0.6789 - val_loss: 1.6974 - learning_rate: 0.0010\n",
            "Epoch 51/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.6088 - loss: 1.9700 - val_accuracy: 0.6585 - val_loss: 1.7207 - learning_rate: 0.0010\n",
            "Epoch 52/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.5923 - loss: 1.9826 - val_accuracy: 0.6626 - val_loss: 1.7616 - learning_rate: 0.0010\n",
            "Epoch 53/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.6128 - loss: 1.9504 - val_accuracy: 0.6911 - val_loss: 1.6685 - learning_rate: 0.0010\n",
            "Epoch 54/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.6467 - loss: 1.9085 - val_accuracy: 0.6057 - val_loss: 1.7642 - learning_rate: 0.0010\n",
            "Epoch 55/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.6496 - loss: 1.9244 - val_accuracy: 0.6992 - val_loss: 1.7030 - learning_rate: 0.0010\n",
            "Epoch 56/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.6145 - loss: 1.9610 - val_accuracy: 0.6423 - val_loss: 1.7750 - learning_rate: 0.0010\n",
            "Epoch 57/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.6426 - loss: 1.8720 - val_accuracy: 0.6992 - val_loss: 1.6468 - learning_rate: 0.0010\n",
            "Epoch 58/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.6545 - loss: 1.9195 - val_accuracy: 0.7033 - val_loss: 1.6991 - learning_rate: 0.0010\n",
            "Epoch 59/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.6697 - loss: 1.9004 - val_accuracy: 0.6789 - val_loss: 1.7049 - learning_rate: 0.0010\n",
            "Epoch 60/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.6078 - loss: 1.9321 - val_accuracy: 0.6870 - val_loss: 1.7375 - learning_rate: 0.0010\n",
            "Epoch 61/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.6641 - loss: 1.8231 - val_accuracy: 0.7033 - val_loss: 1.6486 - learning_rate: 0.0010\n",
            "Epoch 62/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6725 - loss: 1.7899\n",
            "Epoch 62: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.6719 - loss: 1.7906 - val_accuracy: 0.7154 - val_loss: 1.6509 - learning_rate: 0.0010\n",
            "Epoch 63/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.6916 - loss: 1.7788 - val_accuracy: 0.7358 - val_loss: 1.6283 - learning_rate: 5.0000e-04\n",
            "Epoch 64/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.7025 - loss: 1.7474 - val_accuracy: 0.7195 - val_loss: 1.5766 - learning_rate: 5.0000e-04\n",
            "Epoch 65/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.6735 - loss: 1.7910 - val_accuracy: 0.7439 - val_loss: 1.5568 - learning_rate: 5.0000e-04\n",
            "Epoch 66/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.6844 - loss: 1.7157 - val_accuracy: 0.7154 - val_loss: 1.5554 - learning_rate: 5.0000e-04\n",
            "Epoch 67/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.7109 - loss: 1.7487 - val_accuracy: 0.7276 - val_loss: 1.5237 - learning_rate: 5.0000e-04\n",
            "Epoch 68/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.7275 - loss: 1.6827 - val_accuracy: 0.7398 - val_loss: 1.5518 - learning_rate: 5.0000e-04\n",
            "Epoch 69/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.6722 - loss: 1.7598 - val_accuracy: 0.7317 - val_loss: 1.5120 - learning_rate: 5.0000e-04\n",
            "Epoch 70/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.6996 - loss: 1.7103 - val_accuracy: 0.7520 - val_loss: 1.5096 - learning_rate: 5.0000e-04\n",
            "Epoch 71/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.7361 - loss: 1.6978 - val_accuracy: 0.7358 - val_loss: 1.5081 - learning_rate: 5.0000e-04\n",
            "Epoch 72/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.6982 - loss: 1.7404 - val_accuracy: 0.7195 - val_loss: 1.5610 - learning_rate: 5.0000e-04\n",
            "Epoch 73/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.7376 - loss: 1.6496 - val_accuracy: 0.7561 - val_loss: 1.5070 - learning_rate: 5.0000e-04\n",
            "Epoch 74/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.7331 - loss: 1.6521 - val_accuracy: 0.7520 - val_loss: 1.5193 - learning_rate: 5.0000e-04\n",
            "Epoch 75/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.7069 - loss: 1.6910 - val_accuracy: 0.7561 - val_loss: 1.4936 - learning_rate: 5.0000e-04\n",
            "Epoch 76/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.7411 - loss: 1.6848 - val_accuracy: 0.7480 - val_loss: 1.5046 - learning_rate: 5.0000e-04\n",
            "Epoch 77/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.7578 - loss: 1.6036 - val_accuracy: 0.7398 - val_loss: 1.4900 - learning_rate: 5.0000e-04\n",
            "Epoch 78/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.7349 - loss: 1.6478 - val_accuracy: 0.7439 - val_loss: 1.5068 - learning_rate: 5.0000e-04\n",
            "Epoch 79/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.7304 - loss: 1.6169 - val_accuracy: 0.7398 - val_loss: 1.4898 - learning_rate: 5.0000e-04\n",
            "Epoch 80/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.7603 - loss: 1.6644 - val_accuracy: 0.7358 - val_loss: 1.5007 - learning_rate: 5.0000e-04\n",
            "Epoch 81/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.7340 - loss: 1.6376 - val_accuracy: 0.7317 - val_loss: 1.5115 - learning_rate: 5.0000e-04\n",
            "Epoch 82/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.7328 - loss: 1.6368 - val_accuracy: 0.7602 - val_loss: 1.5047 - learning_rate: 5.0000e-04\n",
            "Epoch 83/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.7436 - loss: 1.6332 - val_accuracy: 0.7398 - val_loss: 1.4909 - learning_rate: 5.0000e-04\n",
            "Epoch 84/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.7474 - loss: 1.6065 - val_accuracy: 0.7520 - val_loss: 1.4747 - learning_rate: 5.0000e-04\n",
            "Epoch 85/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.7609 - loss: 1.5965 - val_accuracy: 0.7602 - val_loss: 1.4791 - learning_rate: 5.0000e-04\n",
            "Epoch 86/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.7755 - loss: 1.5874 - val_accuracy: 0.7561 - val_loss: 1.4463 - learning_rate: 5.0000e-04\n",
            "Epoch 87/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.7289 - loss: 1.6653 - val_accuracy: 0.7480 - val_loss: 1.5219 - learning_rate: 5.0000e-04\n",
            "Epoch 88/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.7329 - loss: 1.5971 - val_accuracy: 0.7683 - val_loss: 1.4637 - learning_rate: 5.0000e-04\n",
            "Epoch 89/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.7423 - loss: 1.6260 - val_accuracy: 0.7602 - val_loss: 1.4501 - learning_rate: 5.0000e-04\n",
            "Epoch 90/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.7690 - loss: 1.5588 - val_accuracy: 0.7358 - val_loss: 1.4879 - learning_rate: 5.0000e-04\n",
            "Epoch 91/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7618 - loss: 1.6389\n",
            "Epoch 91: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.7616 - loss: 1.6380 - val_accuracy: 0.7398 - val_loss: 1.5037 - learning_rate: 5.0000e-04\n",
            "Epoch 92/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.7749 - loss: 1.5361 - val_accuracy: 0.7724 - val_loss: 1.4734 - learning_rate: 2.5000e-04\n",
            "Epoch 93/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.7758 - loss: 1.5375 - val_accuracy: 0.7764 - val_loss: 1.4434 - learning_rate: 2.5000e-04\n",
            "Epoch 94/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.8098 - loss: 1.4873 - val_accuracy: 0.7805 - val_loss: 1.4242 - learning_rate: 2.5000e-04\n",
            "Epoch 95/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.7608 - loss: 1.5520 - val_accuracy: 0.7846 - val_loss: 1.4237 - learning_rate: 2.5000e-04\n",
            "Epoch 96/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.7816 - loss: 1.5580 - val_accuracy: 0.7764 - val_loss: 1.4106 - learning_rate: 2.5000e-04\n",
            "Epoch 97/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.8159 - loss: 1.5002 - val_accuracy: 0.7642 - val_loss: 1.4240 - learning_rate: 2.5000e-04\n",
            "Epoch 98/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.7822 - loss: 1.5596 - val_accuracy: 0.7764 - val_loss: 1.4155 - learning_rate: 2.5000e-04\n",
            "Epoch 99/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.7863 - loss: 1.5231 - val_accuracy: 0.7805 - val_loss: 1.4225 - learning_rate: 2.5000e-04\n",
            "Epoch 100/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.8308 - loss: 1.4641 - val_accuracy: 0.7642 - val_loss: 1.4000 - learning_rate: 2.5000e-04\n",
            "Restoring model weights from the end of the best epoch: 100.\n",
            "  âœ… CNN_Attention_v1 Val Acc: 76.42%\n",
            "\n",
            "============================================================\n",
            "ğŸ—ï¸ CNN_Attention_v2 í•™ìŠµ ì¤‘... (LR: 0.0005)\n",
            "============================================================\n",
            "Epoch 1/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 357ms/step - accuracy: 0.0183 - loss: 4.3667 - val_accuracy: 0.0203 - val_loss: 4.2000 - learning_rate: 5.0000e-04\n",
            "Epoch 2/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.0211 - loss: 4.2229 - val_accuracy: 0.0285 - val_loss: 4.1820 - learning_rate: 5.0000e-04\n",
            "Epoch 3/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.0149 - loss: 4.2074 - val_accuracy: 0.0366 - val_loss: 4.1673 - learning_rate: 5.0000e-04\n",
            "Epoch 4/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.0403 - loss: 4.1068 - val_accuracy: 0.0528 - val_loss: 4.0580 - learning_rate: 5.0000e-04\n",
            "Epoch 5/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.0493 - loss: 4.0968 - val_accuracy: 0.0732 - val_loss: 4.0618 - learning_rate: 5.0000e-04\n",
            "Epoch 6/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.0490 - loss: 4.0197 - val_accuracy: 0.0894 - val_loss: 3.8531 - learning_rate: 5.0000e-04\n",
            "Epoch 7/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.0560 - loss: 3.9026 - val_accuracy: 0.1382 - val_loss: 3.8376 - learning_rate: 5.0000e-04\n",
            "Epoch 8/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.0831 - loss: 3.8377 - val_accuracy: 0.1626 - val_loss: 3.6010 - learning_rate: 5.0000e-04\n",
            "Epoch 9/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.0714 - loss: 3.7831 - val_accuracy: 0.1829 - val_loss: 3.4511 - learning_rate: 5.0000e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.1176 - loss: 3.6830 - val_accuracy: 0.2317 - val_loss: 3.3715 - learning_rate: 5.0000e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.1245 - loss: 3.5743 - val_accuracy: 0.2033 - val_loss: 3.2576 - learning_rate: 5.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.1110 - loss: 3.5756 - val_accuracy: 0.2561 - val_loss: 3.1339 - learning_rate: 5.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.1252 - loss: 3.4799 - val_accuracy: 0.2805 - val_loss: 2.9983 - learning_rate: 5.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.1404 - loss: 3.4381 - val_accuracy: 0.3089 - val_loss: 2.9689 - learning_rate: 5.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.1899 - loss: 3.3154 - val_accuracy: 0.3333 - val_loss: 2.9371 - learning_rate: 5.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.1857 - loss: 3.2444 - val_accuracy: 0.3374 - val_loss: 2.8721 - learning_rate: 5.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.2073 - loss: 3.2069 - val_accuracy: 0.3049 - val_loss: 2.7958 - learning_rate: 5.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.1776 - loss: 3.1563 - val_accuracy: 0.3211 - val_loss: 2.7268 - learning_rate: 5.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.2188 - loss: 3.0542 - val_accuracy: 0.3618 - val_loss: 2.6353 - learning_rate: 5.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.2212 - loss: 2.9873 - val_accuracy: 0.3943 - val_loss: 2.5820 - learning_rate: 5.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.2450 - loss: 2.9580 - val_accuracy: 0.3862 - val_loss: 2.5748 - learning_rate: 5.0000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.2729 - loss: 2.9243 - val_accuracy: 0.3862 - val_loss: 2.5016 - learning_rate: 5.0000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.2622 - loss: 2.8620 - val_accuracy: 0.4512 - val_loss: 2.4566 - learning_rate: 5.0000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.3047 - loss: 2.7702 - val_accuracy: 0.4472 - val_loss: 2.4749 - learning_rate: 5.0000e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.3108 - loss: 2.7902 - val_accuracy: 0.4756 - val_loss: 2.3600 - learning_rate: 5.0000e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.2944 - loss: 2.7442 - val_accuracy: 0.4715 - val_loss: 2.3689 - learning_rate: 5.0000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.3268 - loss: 2.6882 - val_accuracy: 0.4431 - val_loss: 2.3306 - learning_rate: 5.0000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.3738 - loss: 2.6364 - val_accuracy: 0.5569 - val_loss: 2.1905 - learning_rate: 5.0000e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.3552 - loss: 2.6105 - val_accuracy: 0.5285 - val_loss: 2.2211 - learning_rate: 5.0000e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.3707 - loss: 2.5861 - val_accuracy: 0.5569 - val_loss: 2.1384 - learning_rate: 5.0000e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.3860 - loss: 2.5330 - val_accuracy: 0.5325 - val_loss: 2.1492 - learning_rate: 5.0000e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.4141 - loss: 2.4676 - val_accuracy: 0.5203 - val_loss: 2.1387 - learning_rate: 5.0000e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.3819 - loss: 2.5243 - val_accuracy: 0.5122 - val_loss: 2.1342 - learning_rate: 5.0000e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.4266 - loss: 2.4956 - val_accuracy: 0.5691 - val_loss: 2.0629 - learning_rate: 5.0000e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.4327 - loss: 2.3862 - val_accuracy: 0.5488 - val_loss: 2.1191 - learning_rate: 5.0000e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.4418 - loss: 2.3471 - val_accuracy: 0.6098 - val_loss: 2.0134 - learning_rate: 5.0000e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.4485 - loss: 2.3745 - val_accuracy: 0.5854 - val_loss: 2.0194 - learning_rate: 5.0000e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.4804 - loss: 2.3341 - val_accuracy: 0.5569 - val_loss: 2.0481 - learning_rate: 5.0000e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.4416 - loss: 2.3276 - val_accuracy: 0.5894 - val_loss: 1.9908 - learning_rate: 5.0000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.4436 - loss: 2.4215 - val_accuracy: 0.6057 - val_loss: 1.9972 - learning_rate: 5.0000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.4327 - loss: 2.3403 - val_accuracy: 0.6016 - val_loss: 1.9966 - learning_rate: 5.0000e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.4898 - loss: 2.2544 - val_accuracy: 0.6220 - val_loss: 1.9493 - learning_rate: 5.0000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.5131 - loss: 2.2305 - val_accuracy: 0.6098 - val_loss: 1.9639 - learning_rate: 5.0000e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.4914 - loss: 2.2458 - val_accuracy: 0.6301 - val_loss: 1.9174 - learning_rate: 5.0000e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.5029 - loss: 2.2498 - val_accuracy: 0.6260 - val_loss: 1.9406 - learning_rate: 5.0000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.5361 - loss: 2.1490 - val_accuracy: 0.6341 - val_loss: 1.8723 - learning_rate: 5.0000e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.5338 - loss: 2.1472 - val_accuracy: 0.5894 - val_loss: 1.9036 - learning_rate: 5.0000e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.5430 - loss: 2.1043 - val_accuracy: 0.6098 - val_loss: 1.9045 - learning_rate: 5.0000e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.5253 - loss: 2.1363 - val_accuracy: 0.6057 - val_loss: 1.9277 - learning_rate: 5.0000e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.5159 - loss: 2.2078 - val_accuracy: 0.6179 - val_loss: 1.8581 - learning_rate: 5.0000e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.5163 - loss: 2.1399 - val_accuracy: 0.6301 - val_loss: 1.8672 - learning_rate: 5.0000e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.5329 - loss: 2.2131 - val_accuracy: 0.6301 - val_loss: 1.8655 - learning_rate: 5.0000e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.5616 - loss: 2.0756 - val_accuracy: 0.6504 - val_loss: 1.8384 - learning_rate: 5.0000e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.5511 - loss: 2.0670 - val_accuracy: 0.6382 - val_loss: 1.8310 - learning_rate: 5.0000e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.5732 - loss: 2.0190 - val_accuracy: 0.6504 - val_loss: 1.8174 - learning_rate: 5.0000e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.6031 - loss: 1.9839 - val_accuracy: 0.6504 - val_loss: 1.8061 - learning_rate: 5.0000e-04\n",
            "Epoch 57/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.6268 - loss: 2.0071 - val_accuracy: 0.6545 - val_loss: 1.8274 - learning_rate: 5.0000e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.6081 - loss: 1.9710 - val_accuracy: 0.6748 - val_loss: 1.7605 - learning_rate: 5.0000e-04\n",
            "Epoch 59/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.5888 - loss: 1.9780 - val_accuracy: 0.6829 - val_loss: 1.7599 - learning_rate: 5.0000e-04\n",
            "Epoch 60/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.6227 - loss: 1.9534 - val_accuracy: 0.6789 - val_loss: 1.7681 - learning_rate: 5.0000e-04\n",
            "Epoch 61/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.5816 - loss: 2.0234 - val_accuracy: 0.6748 - val_loss: 1.7315 - learning_rate: 5.0000e-04\n",
            "Epoch 62/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.6159 - loss: 1.9654 - val_accuracy: 0.6748 - val_loss: 1.7494 - learning_rate: 5.0000e-04\n",
            "Epoch 63/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.6201 - loss: 1.9583 - val_accuracy: 0.6667 - val_loss: 1.7584 - learning_rate: 5.0000e-04\n",
            "Epoch 64/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.6226 - loss: 1.9170 - val_accuracy: 0.6585 - val_loss: 1.7526 - learning_rate: 5.0000e-04\n",
            "Epoch 65/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.6135 - loss: 1.9455 - val_accuracy: 0.6626 - val_loss: 1.7633 - learning_rate: 5.0000e-04\n",
            "Epoch 66/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.5965 - loss: 1.9226 - val_accuracy: 0.7033 - val_loss: 1.7094 - learning_rate: 5.0000e-04\n",
            "Epoch 67/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.6340 - loss: 1.9774 - val_accuracy: 0.6382 - val_loss: 1.8029 - learning_rate: 5.0000e-04\n",
            "Epoch 68/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.6193 - loss: 1.9148 - val_accuracy: 0.6992 - val_loss: 1.7332 - learning_rate: 5.0000e-04\n",
            "Epoch 69/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.6190 - loss: 1.9679 - val_accuracy: 0.6667 - val_loss: 1.7308 - learning_rate: 5.0000e-04\n",
            "Epoch 70/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.6632 - loss: 1.8396 - val_accuracy: 0.6992 - val_loss: 1.7187 - learning_rate: 5.0000e-04\n",
            "Epoch 71/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6920 - loss: 1.8398\n",
            "Epoch 71: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.6914 - loss: 1.8398 - val_accuracy: 0.6829 - val_loss: 1.7267 - learning_rate: 5.0000e-04\n",
            "Epoch 72/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.6486 - loss: 1.8931 - val_accuracy: 0.7033 - val_loss: 1.6811 - learning_rate: 2.5000e-04\n",
            "Epoch 73/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.6816 - loss: 1.8358 - val_accuracy: 0.6951 - val_loss: 1.6641 - learning_rate: 2.5000e-04\n",
            "Epoch 74/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.6578 - loss: 1.8297 - val_accuracy: 0.7276 - val_loss: 1.6649 - learning_rate: 2.5000e-04\n",
            "Epoch 75/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.6717 - loss: 1.7982 - val_accuracy: 0.7114 - val_loss: 1.6766 - learning_rate: 2.5000e-04\n",
            "Epoch 76/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.6640 - loss: 1.8346 - val_accuracy: 0.7114 - val_loss: 1.6383 - learning_rate: 2.5000e-04\n",
            "Epoch 77/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.6832 - loss: 1.7694 - val_accuracy: 0.7114 - val_loss: 1.6377 - learning_rate: 2.5000e-04\n",
            "Epoch 78/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.7072 - loss: 1.7872 - val_accuracy: 0.6951 - val_loss: 1.6354 - learning_rate: 2.5000e-04\n",
            "Epoch 79/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.6798 - loss: 1.8489 - val_accuracy: 0.7195 - val_loss: 1.6315 - learning_rate: 2.5000e-04\n",
            "Epoch 80/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.6813 - loss: 1.7670 - val_accuracy: 0.7195 - val_loss: 1.6296 - learning_rate: 2.5000e-04\n",
            "Epoch 81/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.7143 - loss: 1.7431 - val_accuracy: 0.7195 - val_loss: 1.6498 - learning_rate: 2.5000e-04\n",
            "Epoch 82/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.6693 - loss: 1.8064 - val_accuracy: 0.6992 - val_loss: 1.6207 - learning_rate: 2.5000e-04\n",
            "Epoch 83/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.6970 - loss: 1.7348 - val_accuracy: 0.6951 - val_loss: 1.6301 - learning_rate: 2.5000e-04\n",
            "Epoch 84/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.7291 - loss: 1.7239 - val_accuracy: 0.7236 - val_loss: 1.6071 - learning_rate: 2.5000e-04\n",
            "Epoch 85/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.7026 - loss: 1.7402 - val_accuracy: 0.7317 - val_loss: 1.6122 - learning_rate: 2.5000e-04\n",
            "Epoch 86/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.6836 - loss: 1.7493 - val_accuracy: 0.7195 - val_loss: 1.6248 - learning_rate: 2.5000e-04\n",
            "Epoch 87/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.7292 - loss: 1.7079 - val_accuracy: 0.7236 - val_loss: 1.6065 - learning_rate: 2.5000e-04\n",
            "Epoch 88/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.7401 - loss: 1.6935 - val_accuracy: 0.7154 - val_loss: 1.6190 - learning_rate: 2.5000e-04\n",
            "Epoch 89/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.6986 - loss: 1.7405 - val_accuracy: 0.7073 - val_loss: 1.6201 - learning_rate: 2.5000e-04\n",
            "Epoch 90/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.7116 - loss: 1.7294 - val_accuracy: 0.6951 - val_loss: 1.6041 - learning_rate: 2.5000e-04\n",
            "Epoch 91/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.7143 - loss: 1.6858 - val_accuracy: 0.7236 - val_loss: 1.6022 - learning_rate: 2.5000e-04\n",
            "Epoch 92/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.7376 - loss: 1.6664 - val_accuracy: 0.7154 - val_loss: 1.6228 - learning_rate: 2.5000e-04\n",
            "Epoch 93/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.7398 - loss: 1.6591 - val_accuracy: 0.7317 - val_loss: 1.5918 - learning_rate: 2.5000e-04\n",
            "Epoch 94/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.7385 - loss: 1.6549 - val_accuracy: 0.7398 - val_loss: 1.5882 - learning_rate: 2.5000e-04\n",
            "Epoch 95/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.7123 - loss: 1.6739 - val_accuracy: 0.7154 - val_loss: 1.5788 - learning_rate: 2.5000e-04\n",
            "Epoch 96/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.7270 - loss: 1.6647 - val_accuracy: 0.7276 - val_loss: 1.5812 - learning_rate: 2.5000e-04\n",
            "Epoch 97/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.7464 - loss: 1.6822 - val_accuracy: 0.7317 - val_loss: 1.5717 - learning_rate: 2.5000e-04\n",
            "Epoch 98/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.7046 - loss: 1.6920 - val_accuracy: 0.7276 - val_loss: 1.5906 - learning_rate: 2.5000e-04\n",
            "Epoch 99/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.7375 - loss: 1.6530 - val_accuracy: 0.7276 - val_loss: 1.5722 - learning_rate: 2.5000e-04\n",
            "Epoch 100/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.7093 - loss: 1.6860 - val_accuracy: 0.7358 - val_loss: 1.5723 - learning_rate: 2.5000e-04\n",
            "Restoring model weights from the end of the best epoch: 97.\n",
            "  âœ… CNN_Attention_v2 Val Acc: 73.17%\n",
            "\n",
            "============================================================\n",
            "ğŸ—ï¸ BiLSTM_Attention_v1 í•™ìŠµ ì¤‘... (LR: 0.001)\n",
            "============================================================\n",
            "Epoch 1/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 65ms/step - accuracy: 0.0156 - loss: 4.5292 - val_accuracy: 0.0285 - val_loss: 4.1558 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.0211 - loss: 4.2178 - val_accuracy: 0.0285 - val_loss: 4.1283 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.0279 - loss: 4.1717 - val_accuracy: 0.0285 - val_loss: 4.1107 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.0264 - loss: 4.0988 - val_accuracy: 0.0325 - val_loss: 3.9820 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - accuracy: 0.0142 - loss: 4.0495 - val_accuracy: 0.0325 - val_loss: 3.8787 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.0226 - loss: 4.0029 - val_accuracy: 0.0650 - val_loss: 3.8393 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.0299 - loss: 3.9442 - val_accuracy: 0.0650 - val_loss: 3.7032 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.0373 - loss: 3.8484 - val_accuracy: 0.0569 - val_loss: 3.6585 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.0459 - loss: 3.8775 - val_accuracy: 0.0894 - val_loss: 3.5844 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.0534 - loss: 3.8066 - val_accuracy: 0.0732 - val_loss: 3.5524 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - accuracy: 0.0619 - loss: 3.7651 - val_accuracy: 0.0732 - val_loss: 3.4418 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.0658 - loss: 3.6882 - val_accuracy: 0.1260 - val_loss: 3.3618 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.0658 - loss: 3.6810 - val_accuracy: 0.1423 - val_loss: 3.3560 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.0918 - loss: 3.5571 - val_accuracy: 0.1463 - val_loss: 3.3077 - learning_rate: 0.0010\n",
            "Epoch 15/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.0793 - loss: 3.5918 - val_accuracy: 0.1545 - val_loss: 3.2017 - learning_rate: 0.0010\n",
            "Epoch 16/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.1057 - loss: 3.4297 - val_accuracy: 0.1545 - val_loss: 3.1332 - learning_rate: 0.0010\n",
            "Epoch 17/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.0980 - loss: 3.5063 - val_accuracy: 0.1829 - val_loss: 3.1867 - learning_rate: 0.0010\n",
            "Epoch 18/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.1302 - loss: 3.3851 - val_accuracy: 0.2154 - val_loss: 2.9789 - learning_rate: 0.0010\n",
            "Epoch 19/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 66ms/step - accuracy: 0.1271 - loss: 3.3584 - val_accuracy: 0.2033 - val_loss: 2.9655 - learning_rate: 0.0010\n",
            "Epoch 20/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.1555 - loss: 3.2753 - val_accuracy: 0.2480 - val_loss: 3.0059 - learning_rate: 0.0010\n",
            "Epoch 21/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.1426 - loss: 3.2674 - val_accuracy: 0.2724 - val_loss: 2.8789 - learning_rate: 0.0010\n",
            "Epoch 22/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.1598 - loss: 3.1698 - val_accuracy: 0.2846 - val_loss: 2.7716 - learning_rate: 0.0010\n",
            "Epoch 23/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.1575 - loss: 3.1425 - val_accuracy: 0.2886 - val_loss: 2.7233 - learning_rate: 0.0010\n",
            "Epoch 24/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.2075 - loss: 3.0302 - val_accuracy: 0.2846 - val_loss: 2.7045 - learning_rate: 0.0010\n",
            "Epoch 25/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.1894 - loss: 3.0800 - val_accuracy: 0.3374 - val_loss: 2.6499 - learning_rate: 0.0010\n",
            "Epoch 26/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - accuracy: 0.2012 - loss: 3.0045 - val_accuracy: 0.3455 - val_loss: 2.6387 - learning_rate: 0.0010\n",
            "Epoch 27/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 0.2401 - loss: 2.8947 - val_accuracy: 0.3415 - val_loss: 2.6011 - learning_rate: 0.0010\n",
            "Epoch 28/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.2408 - loss: 2.9431 - val_accuracy: 0.3577 - val_loss: 2.5430 - learning_rate: 0.0010\n",
            "Epoch 29/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.2620 - loss: 2.8522 - val_accuracy: 0.3821 - val_loss: 2.5221 - learning_rate: 0.0010\n",
            "Epoch 30/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.2894 - loss: 2.8342 - val_accuracy: 0.3293 - val_loss: 2.5117 - learning_rate: 0.0010\n",
            "Epoch 31/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.2490 - loss: 2.8775 - val_accuracy: 0.3252 - val_loss: 2.5077 - learning_rate: 0.0010\n",
            "Epoch 32/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.2742 - loss: 2.8226 - val_accuracy: 0.3780 - val_loss: 2.4454 - learning_rate: 0.0010\n",
            "Epoch 33/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.3174 - loss: 2.7072 - val_accuracy: 0.3943 - val_loss: 2.4133 - learning_rate: 0.0010\n",
            "Epoch 34/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.3495 - loss: 2.6178 - val_accuracy: 0.4228 - val_loss: 2.3268 - learning_rate: 0.0010\n",
            "Epoch 35/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - accuracy: 0.3376 - loss: 2.6434 - val_accuracy: 0.4593 - val_loss: 2.3429 - learning_rate: 0.0010\n",
            "Epoch 36/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.3551 - loss: 2.5904 - val_accuracy: 0.4390 - val_loss: 2.2820 - learning_rate: 0.0010\n",
            "Epoch 37/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.3449 - loss: 2.5649 - val_accuracy: 0.4268 - val_loss: 2.2681 - learning_rate: 0.0010\n",
            "Epoch 38/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.3537 - loss: 2.5247 - val_accuracy: 0.4837 - val_loss: 2.2454 - learning_rate: 0.0010\n",
            "Epoch 39/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.3855 - loss: 2.5667 - val_accuracy: 0.4919 - val_loss: 2.2408 - learning_rate: 0.0010\n",
            "Epoch 40/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.4119 - loss: 2.4418 - val_accuracy: 0.4959 - val_loss: 2.1834 - learning_rate: 0.0010\n",
            "Epoch 41/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.4124 - loss: 2.4303 - val_accuracy: 0.4715 - val_loss: 2.1259 - learning_rate: 0.0010\n",
            "Epoch 42/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.4186 - loss: 2.4676 - val_accuracy: 0.5366 - val_loss: 2.1171 - learning_rate: 0.0010\n",
            "Epoch 43/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.4119 - loss: 2.4200 - val_accuracy: 0.5407 - val_loss: 2.1203 - learning_rate: 0.0010\n",
            "Epoch 44/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - accuracy: 0.3997 - loss: 2.3881 - val_accuracy: 0.5732 - val_loss: 2.0798 - learning_rate: 0.0010\n",
            "Epoch 45/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.4262 - loss: 2.3721 - val_accuracy: 0.5285 - val_loss: 2.0761 - learning_rate: 0.0010\n",
            "Epoch 46/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.4667 - loss: 2.2728 - val_accuracy: 0.5569 - val_loss: 2.0746 - learning_rate: 0.0010\n",
            "Epoch 47/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.4575 - loss: 2.3113 - val_accuracy: 0.5407 - val_loss: 2.0356 - learning_rate: 0.0010\n",
            "Epoch 48/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.4543 - loss: 2.3168 - val_accuracy: 0.5691 - val_loss: 1.9738 - learning_rate: 0.0010\n",
            "Epoch 49/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.4864 - loss: 2.2715 - val_accuracy: 0.5894 - val_loss: 1.9708 - learning_rate: 0.0010\n",
            "Epoch 50/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.4612 - loss: 2.2631 - val_accuracy: 0.5976 - val_loss: 1.9761 - learning_rate: 0.0010\n",
            "Epoch 51/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.4969 - loss: 2.2246 - val_accuracy: 0.5976 - val_loss: 1.9578 - learning_rate: 0.0010\n",
            "Epoch 52/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.4884 - loss: 2.3028 - val_accuracy: 0.5610 - val_loss: 1.9227 - learning_rate: 0.0010\n",
            "Epoch 53/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - accuracy: 0.5329 - loss: 2.1556 - val_accuracy: 0.5813 - val_loss: 1.9886 - learning_rate: 0.0010\n",
            "Epoch 54/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.5084 - loss: 2.1304 - val_accuracy: 0.6138 - val_loss: 1.9307 - learning_rate: 0.0010\n",
            "Epoch 55/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.5231 - loss: 2.1223 - val_accuracy: 0.5813 - val_loss: 1.9351 - learning_rate: 0.0010\n",
            "Epoch 56/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.5489 - loss: 2.1023 - val_accuracy: 0.6016 - val_loss: 1.9304 - learning_rate: 0.0010\n",
            "Epoch 57/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.5727 - loss: 2.0219 - val_accuracy: 0.6179 - val_loss: 1.8591 - learning_rate: 0.0010\n",
            "Epoch 58/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.5990 - loss: 1.9964 - val_accuracy: 0.6545 - val_loss: 1.8474 - learning_rate: 0.0010\n",
            "Epoch 59/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.5646 - loss: 2.0584 - val_accuracy: 0.6138 - val_loss: 1.9072 - learning_rate: 0.0010\n",
            "Epoch 60/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.5627 - loss: 2.0519 - val_accuracy: 0.6179 - val_loss: 1.8286 - learning_rate: 0.0010\n",
            "Epoch 61/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 62ms/step - accuracy: 0.6009 - loss: 2.0469 - val_accuracy: 0.6545 - val_loss: 1.8221 - learning_rate: 0.0010\n",
            "Epoch 62/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.6238 - loss: 1.9395 - val_accuracy: 0.6341 - val_loss: 1.8251 - learning_rate: 0.0010\n",
            "Epoch 63/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.6015 - loss: 1.9731 - val_accuracy: 0.6341 - val_loss: 1.8546 - learning_rate: 0.0010\n",
            "Epoch 64/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.6132 - loss: 1.9480 - val_accuracy: 0.6545 - val_loss: 1.8115 - learning_rate: 0.0010\n",
            "Epoch 65/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.6435 - loss: 1.8849 - val_accuracy: 0.6667 - val_loss: 1.7979 - learning_rate: 0.0010\n",
            "Epoch 66/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.6181 - loss: 1.9279 - val_accuracy: 0.6220 - val_loss: 1.8108 - learning_rate: 0.0010\n",
            "Epoch 67/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.6092 - loss: 1.9158 - val_accuracy: 0.6138 - val_loss: 1.8668 - learning_rate: 0.0010\n",
            "Epoch 68/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.6182 - loss: 1.9295 - val_accuracy: 0.6545 - val_loss: 1.7153 - learning_rate: 0.0010\n",
            "Epoch 69/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.6281 - loss: 1.9374 - val_accuracy: 0.6423 - val_loss: 1.7263 - learning_rate: 0.0010\n",
            "Epoch 70/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 0.6604 - loss: 1.8662 - val_accuracy: 0.6626 - val_loss: 1.7940 - learning_rate: 0.0010\n",
            "Epoch 71/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.6663 - loss: 1.8527 - val_accuracy: 0.6260 - val_loss: 1.7882 - learning_rate: 0.0010\n",
            "Epoch 72/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.6461 - loss: 1.8922 - val_accuracy: 0.6911 - val_loss: 1.7257 - learning_rate: 0.0010\n",
            "Epoch 73/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6737 - loss: 1.7822\n",
            "Epoch 73: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.6734 - loss: 1.7833 - val_accuracy: 0.6667 - val_loss: 1.7657 - learning_rate: 0.0010\n",
            "Epoch 74/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.6918 - loss: 1.7716 - val_accuracy: 0.6911 - val_loss: 1.6668 - learning_rate: 5.0000e-04\n",
            "Epoch 75/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.6996 - loss: 1.7724 - val_accuracy: 0.7033 - val_loss: 1.6161 - learning_rate: 5.0000e-04\n",
            "Epoch 76/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.7578 - loss: 1.6775 - val_accuracy: 0.7236 - val_loss: 1.6258 - learning_rate: 5.0000e-04\n",
            "Epoch 77/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 0.7185 - loss: 1.7129 - val_accuracy: 0.6870 - val_loss: 1.6139 - learning_rate: 5.0000e-04\n",
            "Epoch 78/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.6924 - loss: 1.7232 - val_accuracy: 0.6951 - val_loss: 1.6305 - learning_rate: 5.0000e-04\n",
            "Epoch 79/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.7468 - loss: 1.6741 - val_accuracy: 0.7114 - val_loss: 1.6076 - learning_rate: 5.0000e-04\n",
            "Epoch 80/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.7528 - loss: 1.6160 - val_accuracy: 0.7114 - val_loss: 1.6494 - learning_rate: 5.0000e-04\n",
            "Epoch 81/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.7472 - loss: 1.6538 - val_accuracy: 0.7073 - val_loss: 1.6038 - learning_rate: 5.0000e-04\n",
            "Epoch 82/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.7174 - loss: 1.6568 - val_accuracy: 0.7154 - val_loss: 1.5907 - learning_rate: 5.0000e-04\n",
            "Epoch 83/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.7618 - loss: 1.6400 - val_accuracy: 0.7033 - val_loss: 1.6039 - learning_rate: 5.0000e-04\n",
            "Epoch 84/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.7891 - loss: 1.5594 - val_accuracy: 0.6992 - val_loss: 1.6487 - learning_rate: 5.0000e-04\n",
            "Epoch 85/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.7596 - loss: 1.6182 - val_accuracy: 0.7033 - val_loss: 1.5860 - learning_rate: 5.0000e-04\n",
            "Epoch 86/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.7473 - loss: 1.6149 - val_accuracy: 0.6951 - val_loss: 1.6275 - learning_rate: 5.0000e-04\n",
            "Epoch 87/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 0.8140 - loss: 1.5238 - val_accuracy: 0.6951 - val_loss: 1.5839 - learning_rate: 5.0000e-04\n",
            "Epoch 88/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.7802 - loss: 1.5926 - val_accuracy: 0.7114 - val_loss: 1.6058 - learning_rate: 5.0000e-04\n",
            "Epoch 89/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.7331 - loss: 1.6529 - val_accuracy: 0.7033 - val_loss: 1.5798 - learning_rate: 5.0000e-04\n",
            "Epoch 90/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.7746 - loss: 1.5563 - val_accuracy: 0.7236 - val_loss: 1.5894 - learning_rate: 5.0000e-04\n",
            "Epoch 91/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.7689 - loss: 1.5337 - val_accuracy: 0.7033 - val_loss: 1.5509 - learning_rate: 5.0000e-04\n",
            "Epoch 92/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.7509 - loss: 1.6032 - val_accuracy: 0.7317 - val_loss: 1.5775 - learning_rate: 5.0000e-04\n",
            "Epoch 93/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.7875 - loss: 1.5319 - val_accuracy: 0.7114 - val_loss: 1.5844 - learning_rate: 5.0000e-04\n",
            "Epoch 94/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.7435 - loss: 1.5839 - val_accuracy: 0.7317 - val_loss: 1.5529 - learning_rate: 5.0000e-04\n",
            "Epoch 95/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.7872 - loss: 1.5420 - val_accuracy: 0.7195 - val_loss: 1.5575 - learning_rate: 5.0000e-04\n",
            "Epoch 96/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 0.8266 - loss: 1.4582 - val_accuracy: 0.7561 - val_loss: 1.5370 - learning_rate: 5.0000e-04\n",
            "Epoch 97/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.7672 - loss: 1.5486 - val_accuracy: 0.7195 - val_loss: 1.5774 - learning_rate: 5.0000e-04\n",
            "Epoch 98/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.8272 - loss: 1.4857 - val_accuracy: 0.7154 - val_loss: 1.5553 - learning_rate: 5.0000e-04\n",
            "Epoch 99/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.7972 - loss: 1.5542 - val_accuracy: 0.7439 - val_loss: 1.5380 - learning_rate: 5.0000e-04\n",
            "Epoch 100/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.7816 - loss: 1.5036 - val_accuracy: 0.7073 - val_loss: 1.5409 - learning_rate: 5.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 96.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 17 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x784f3263d760> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  âœ… BiLSTM_Attention_v1 Val Acc: 75.61%\n",
            "\n",
            "============================================================\n",
            "ğŸ—ï¸ BiLSTM_Attention_v2 í•™ìŠµ ì¤‘... (LR: 0.0005)\n",
            "============================================================\n",
            "Epoch 1/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - accuracy: 0.0175 - loss: 4.5861 - val_accuracy: 0.0488 - val_loss: 4.1529 - learning_rate: 5.0000e-04\n",
            "Epoch 2/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.0166 - loss: 4.1880 - val_accuracy: 0.0407 - val_loss: 4.0810 - learning_rate: 5.0000e-04\n",
            "Epoch 3/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.0247 - loss: 4.1338 - val_accuracy: 0.0407 - val_loss: 4.0133 - learning_rate: 5.0000e-04\n",
            "Epoch 4/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.0358 - loss: 4.1066 - val_accuracy: 0.0610 - val_loss: 3.9440 - learning_rate: 5.0000e-04\n",
            "Epoch 5/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.0558 - loss: 3.9980 - val_accuracy: 0.1098 - val_loss: 3.7428 - learning_rate: 5.0000e-04\n",
            "Epoch 6/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - accuracy: 0.0595 - loss: 3.9172 - val_accuracy: 0.1585 - val_loss: 3.5799 - learning_rate: 5.0000e-04\n",
            "Epoch 7/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.0940 - loss: 3.7281 - val_accuracy: 0.2073 - val_loss: 3.4485 - learning_rate: 5.0000e-04\n",
            "Epoch 8/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.1044 - loss: 3.6496 - val_accuracy: 0.1870 - val_loss: 3.3123 - learning_rate: 5.0000e-04\n",
            "Epoch 9/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 0.1263 - loss: 3.5656 - val_accuracy: 0.2439 - val_loss: 3.1590 - learning_rate: 5.0000e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.1335 - loss: 3.4855 - val_accuracy: 0.2846 - val_loss: 2.9726 - learning_rate: 5.0000e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.1783 - loss: 3.3042 - val_accuracy: 0.2967 - val_loss: 2.8863 - learning_rate: 5.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.1825 - loss: 3.2580 - val_accuracy: 0.3171 - val_loss: 2.7895 - learning_rate: 5.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.2584 - loss: 3.0040 - val_accuracy: 0.3496 - val_loss: 2.6690 - learning_rate: 5.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.2376 - loss: 3.0218 - val_accuracy: 0.3984 - val_loss: 2.5421 - learning_rate: 5.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.2763 - loss: 2.9116 - val_accuracy: 0.4065 - val_loss: 2.5171 - learning_rate: 5.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.3027 - loss: 2.8587 - val_accuracy: 0.4146 - val_loss: 2.4800 - learning_rate: 5.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - accuracy: 0.2832 - loss: 2.8323 - val_accuracy: 0.4309 - val_loss: 2.4384 - learning_rate: 5.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.3405 - loss: 2.7773 - val_accuracy: 0.5122 - val_loss: 2.2805 - learning_rate: 5.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.3531 - loss: 2.6523 - val_accuracy: 0.4756 - val_loss: 2.2386 - learning_rate: 5.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.3912 - loss: 2.5777 - val_accuracy: 0.4634 - val_loss: 2.2861 - learning_rate: 5.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.3950 - loss: 2.5441 - val_accuracy: 0.5203 - val_loss: 2.1643 - learning_rate: 5.0000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.3758 - loss: 2.5201 - val_accuracy: 0.5122 - val_loss: 2.1728 - learning_rate: 5.0000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.4088 - loss: 2.4771 - val_accuracy: 0.5244 - val_loss: 2.0992 - learning_rate: 5.0000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.4685 - loss: 2.3843 - val_accuracy: 0.5569 - val_loss: 2.0488 - learning_rate: 5.0000e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.4508 - loss: 2.3855 - val_accuracy: 0.5447 - val_loss: 2.0731 - learning_rate: 5.0000e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.4413 - loss: 2.4327 - val_accuracy: 0.5894 - val_loss: 1.9991 - learning_rate: 5.0000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.4518 - loss: 2.3754 - val_accuracy: 0.5691 - val_loss: 2.0337 - learning_rate: 5.0000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.4565 - loss: 2.3384 - val_accuracy: 0.5935 - val_loss: 1.9817 - learning_rate: 5.0000e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.4976 - loss: 2.2773 - val_accuracy: 0.5488 - val_loss: 2.0070 - learning_rate: 5.0000e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.5030 - loss: 2.2697 - val_accuracy: 0.6016 - val_loss: 1.9325 - learning_rate: 5.0000e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.5595 - loss: 2.1351 - val_accuracy: 0.5976 - val_loss: 1.9676 - learning_rate: 5.0000e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.5243 - loss: 2.1767 - val_accuracy: 0.6179 - val_loss: 1.9246 - learning_rate: 5.0000e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.5191 - loss: 2.2090 - val_accuracy: 0.6220 - val_loss: 1.9136 - learning_rate: 5.0000e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.5400 - loss: 2.1423 - val_accuracy: 0.6341 - val_loss: 1.9035 - learning_rate: 5.0000e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - accuracy: 0.5340 - loss: 2.1203 - val_accuracy: 0.6504 - val_loss: 1.9085 - learning_rate: 5.0000e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.5580 - loss: 2.0999 - val_accuracy: 0.6016 - val_loss: 1.8924 - learning_rate: 5.0000e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.5731 - loss: 2.0426 - val_accuracy: 0.6301 - val_loss: 1.8676 - learning_rate: 5.0000e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.5604 - loss: 2.0997 - val_accuracy: 0.6423 - val_loss: 1.8458 - learning_rate: 5.0000e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.5847 - loss: 2.0082 - val_accuracy: 0.6382 - val_loss: 1.8137 - learning_rate: 5.0000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.5837 - loss: 2.0466 - val_accuracy: 0.6463 - val_loss: 1.8283 - learning_rate: 5.0000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.6162 - loss: 1.9774 - val_accuracy: 0.6260 - val_loss: 1.8310 - learning_rate: 5.0000e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.5982 - loss: 2.0666 - val_accuracy: 0.6748 - val_loss: 1.8023 - learning_rate: 5.0000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.6512 - loss: 1.8845 - val_accuracy: 0.6667 - val_loss: 1.7655 - learning_rate: 5.0000e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.6391 - loss: 1.9172 - val_accuracy: 0.6504 - val_loss: 1.8089 - learning_rate: 5.0000e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.6252 - loss: 1.9311 - val_accuracy: 0.6911 - val_loss: 1.7297 - learning_rate: 5.0000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - accuracy: 0.6285 - loss: 1.9165 - val_accuracy: 0.6748 - val_loss: 1.7441 - learning_rate: 5.0000e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - accuracy: 0.6415 - loss: 1.8783 - val_accuracy: 0.6992 - val_loss: 1.7463 - learning_rate: 5.0000e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.6453 - loss: 1.8679 - val_accuracy: 0.6748 - val_loss: 1.7537 - learning_rate: 5.0000e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 0.6656 - loss: 1.8772 - val_accuracy: 0.6911 - val_loss: 1.6911 - learning_rate: 5.0000e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.6644 - loss: 1.8093 - val_accuracy: 0.6748 - val_loss: 1.7341 - learning_rate: 5.0000e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.6724 - loss: 1.8141 - val_accuracy: 0.6870 - val_loss: 1.6955 - learning_rate: 5.0000e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.6962 - loss: 1.7628 - val_accuracy: 0.6504 - val_loss: 1.7646 - learning_rate: 5.0000e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.6774 - loss: 1.7954 - val_accuracy: 0.6911 - val_loss: 1.7306 - learning_rate: 5.0000e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m30/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6889 - loss: 1.8044\n",
            "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.6880 - loss: 1.8058 - val_accuracy: 0.6748 - val_loss: 1.7574 - learning_rate: 5.0000e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.7133 - loss: 1.7565 - val_accuracy: 0.6992 - val_loss: 1.6739 - learning_rate: 2.5000e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.6796 - loss: 1.7962 - val_accuracy: 0.7114 - val_loss: 1.6308 - learning_rate: 2.5000e-04\n",
            "Epoch 57/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.7342 - loss: 1.6777 - val_accuracy: 0.6992 - val_loss: 1.6479 - learning_rate: 2.5000e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.7462 - loss: 1.6607 - val_accuracy: 0.7276 - val_loss: 1.6257 - learning_rate: 2.5000e-04\n",
            "Epoch 59/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 0.7477 - loss: 1.6072 - val_accuracy: 0.7033 - val_loss: 1.6354 - learning_rate: 2.5000e-04\n",
            "Epoch 60/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.7180 - loss: 1.6805 - val_accuracy: 0.7033 - val_loss: 1.5932 - learning_rate: 2.5000e-04\n",
            "Epoch 61/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.7496 - loss: 1.6140 - val_accuracy: 0.7073 - val_loss: 1.6145 - learning_rate: 2.5000e-04\n",
            "Epoch 62/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.7962 - loss: 1.5696 - val_accuracy: 0.7358 - val_loss: 1.6034 - learning_rate: 2.5000e-04\n",
            "Epoch 63/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - accuracy: 0.7509 - loss: 1.6452 - val_accuracy: 0.7358 - val_loss: 1.6017 - learning_rate: 2.5000e-04\n",
            "Epoch 64/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.7555 - loss: 1.6055 - val_accuracy: 0.7033 - val_loss: 1.6096 - learning_rate: 2.5000e-04\n",
            "Epoch 65/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.7563 - loss: 1.6140 - val_accuracy: 0.7154 - val_loss: 1.5887 - learning_rate: 2.5000e-04\n",
            "Epoch 66/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.7598 - loss: 1.5929 - val_accuracy: 0.7602 - val_loss: 1.5657 - learning_rate: 2.5000e-04\n",
            "Epoch 67/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 0.7929 - loss: 1.5217 - val_accuracy: 0.7154 - val_loss: 1.5837 - learning_rate: 2.5000e-04\n",
            "Epoch 68/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.7615 - loss: 1.5566 - val_accuracy: 0.7276 - val_loss: 1.5630 - learning_rate: 2.5000e-04\n",
            "Epoch 69/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.7464 - loss: 1.5812 - val_accuracy: 0.7276 - val_loss: 1.5801 - learning_rate: 2.5000e-04\n",
            "Epoch 70/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.7967 - loss: 1.5826 - val_accuracy: 0.7317 - val_loss: 1.5658 - learning_rate: 2.5000e-04\n",
            "Epoch 71/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.7648 - loss: 1.5864 - val_accuracy: 0.7195 - val_loss: 1.5595 - learning_rate: 2.5000e-04\n",
            "Epoch 72/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.8072 - loss: 1.5228 - val_accuracy: 0.7358 - val_loss: 1.5591 - learning_rate: 2.5000e-04\n",
            "Epoch 73/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.7896 - loss: 1.5545 - val_accuracy: 0.7276 - val_loss: 1.5896 - learning_rate: 2.5000e-04\n",
            "Epoch 74/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.7739 - loss: 1.5617 - val_accuracy: 0.7398 - val_loss: 1.5477 - learning_rate: 2.5000e-04\n",
            "Epoch 75/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.7771 - loss: 1.5892 - val_accuracy: 0.7033 - val_loss: 1.5620 - learning_rate: 2.5000e-04\n",
            "Epoch 76/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - accuracy: 0.7782 - loss: 1.5597 - val_accuracy: 0.7480 - val_loss: 1.5335 - learning_rate: 2.5000e-04\n",
            "Epoch 77/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - accuracy: 0.7817 - loss: 1.5277 - val_accuracy: 0.7602 - val_loss: 1.5382 - learning_rate: 2.5000e-04\n",
            "Epoch 78/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.7899 - loss: 1.4951 - val_accuracy: 0.7358 - val_loss: 1.5352 - learning_rate: 2.5000e-04\n",
            "Epoch 79/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.7759 - loss: 1.5178 - val_accuracy: 0.7439 - val_loss: 1.5484 - learning_rate: 2.5000e-04\n",
            "Epoch 80/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.8345 - loss: 1.4593 - val_accuracy: 0.7602 - val_loss: 1.5246 - learning_rate: 2.5000e-04\n",
            "Epoch 81/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.7680 - loss: 1.5563 - val_accuracy: 0.7602 - val_loss: 1.5432 - learning_rate: 2.5000e-04\n",
            "Epoch 82/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.8077 - loss: 1.5139 - val_accuracy: 0.7358 - val_loss: 1.5624 - learning_rate: 2.5000e-04\n",
            "Epoch 83/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.7906 - loss: 1.5568 - val_accuracy: 0.7480 - val_loss: 1.5776 - learning_rate: 2.5000e-04\n",
            "Epoch 84/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.8015 - loss: 1.5431 - val_accuracy: 0.7642 - val_loss: 1.5372 - learning_rate: 2.5000e-04\n",
            "Epoch 85/100\n",
            "\u001b[1m30/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.8167 - loss: 1.5174\n",
            "Epoch 85: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.8163 - loss: 1.5166 - val_accuracy: 0.7480 - val_loss: 1.5619 - learning_rate: 2.5000e-04\n",
            "Epoch 86/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.8068 - loss: 1.4935 - val_accuracy: 0.7561 - val_loss: 1.5165 - learning_rate: 1.2500e-04\n",
            "Epoch 87/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.8060 - loss: 1.4728 - val_accuracy: 0.7642 - val_loss: 1.5454 - learning_rate: 1.2500e-04\n",
            "Epoch 88/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.8294 - loss: 1.4794 - val_accuracy: 0.7520 - val_loss: 1.5200 - learning_rate: 1.2500e-04\n",
            "Epoch 89/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.8185 - loss: 1.4920 - val_accuracy: 0.7561 - val_loss: 1.5108 - learning_rate: 1.2500e-04\n",
            "Epoch 90/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.8505 - loss: 1.3854 - val_accuracy: 0.7561 - val_loss: 1.5313 - learning_rate: 1.2500e-04\n",
            "Epoch 91/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.8258 - loss: 1.4595 - val_accuracy: 0.7358 - val_loss: 1.5274 - learning_rate: 1.2500e-04\n",
            "Epoch 92/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.8485 - loss: 1.4053 - val_accuracy: 0.7520 - val_loss: 1.5367 - learning_rate: 1.2500e-04\n",
            "Epoch 93/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.8369 - loss: 1.4176 - val_accuracy: 0.7561 - val_loss: 1.5338 - learning_rate: 1.2500e-04\n",
            "Epoch 94/100\n",
            "\u001b[1m30/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.8440 - loss: 1.4463\n",
            "Epoch 94: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 0.8448 - loss: 1.4441 - val_accuracy: 0.7683 - val_loss: 1.5343 - learning_rate: 1.2500e-04\n",
            "Epoch 95/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 0.8373 - loss: 1.3859 - val_accuracy: 0.7724 - val_loss: 1.5215 - learning_rate: 6.2500e-05\n",
            "Epoch 96/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 0.8512 - loss: 1.4019 - val_accuracy: 0.7561 - val_loss: 1.5106 - learning_rate: 6.2500e-05\n",
            "Epoch 97/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.8517 - loss: 1.4139 - val_accuracy: 0.7520 - val_loss: 1.5149 - learning_rate: 6.2500e-05\n",
            "Epoch 98/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.8459 - loss: 1.3685 - val_accuracy: 0.7561 - val_loss: 1.5264 - learning_rate: 6.2500e-05\n",
            "Epoch 99/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.8613 - loss: 1.3765 - val_accuracy: 0.7561 - val_loss: 1.5148 - learning_rate: 6.2500e-05\n",
            "Epoch 100/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.8451 - loss: 1.4369 - val_accuracy: 0.7480 - val_loss: 1.5034 - learning_rate: 6.2500e-05\n",
            "Restoring model weights from the end of the best epoch: 100.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 17 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x784f3c9ba480> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  âœ… BiLSTM_Attention_v2 Val Acc: 74.80%\n",
            "\n",
            "============================================================\n",
            "ğŸ—ï¸ Transformer_v1 í•™ìŠµ ì¤‘... (LR: 0.0008)\n",
            "============================================================\n",
            "Epoch 1/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 459ms/step - accuracy: 0.0164 - loss: 4.3150 - val_accuracy: 0.0691 - val_loss: 4.0631 - learning_rate: 8.0000e-04\n",
            "Epoch 2/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.0378 - loss: 4.0440 - val_accuracy: 0.1016 - val_loss: 3.8010 - learning_rate: 8.0000e-04\n",
            "Epoch 3/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.0787 - loss: 3.8982 - val_accuracy: 0.1992 - val_loss: 3.3971 - learning_rate: 8.0000e-04\n",
            "Epoch 4/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.1925 - loss: 3.4742 - val_accuracy: 0.3089 - val_loss: 2.9983 - learning_rate: 8.0000e-04\n",
            "Epoch 5/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.1868 - loss: 3.2049 - val_accuracy: 0.2846 - val_loss: 2.8200 - learning_rate: 8.0000e-04\n",
            "Epoch 6/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.2800 - loss: 2.8974 - val_accuracy: 0.3902 - val_loss: 2.5554 - learning_rate: 8.0000e-04\n",
            "Epoch 7/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.3523 - loss: 2.6900 - val_accuracy: 0.4106 - val_loss: 2.4324 - learning_rate: 8.0000e-04\n",
            "Epoch 8/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.3760 - loss: 2.5861 - val_accuracy: 0.5285 - val_loss: 2.1823 - learning_rate: 8.0000e-04\n",
            "Epoch 9/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.4560 - loss: 2.3151 - val_accuracy: 0.5488 - val_loss: 2.0785 - learning_rate: 8.0000e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.5266 - loss: 2.1874 - val_accuracy: 0.5610 - val_loss: 2.0676 - learning_rate: 8.0000e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.5100 - loss: 2.1783 - val_accuracy: 0.6016 - val_loss: 1.9200 - learning_rate: 8.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.5814 - loss: 2.0008 - val_accuracy: 0.5935 - val_loss: 1.8901 - learning_rate: 8.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.6290 - loss: 1.8955 - val_accuracy: 0.6179 - val_loss: 1.8406 - learning_rate: 8.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.6343 - loss: 1.9087 - val_accuracy: 0.6016 - val_loss: 1.8160 - learning_rate: 8.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.6627 - loss: 1.7911 - val_accuracy: 0.6301 - val_loss: 1.8368 - learning_rate: 8.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.6562 - loss: 1.8071 - val_accuracy: 0.6423 - val_loss: 1.7689 - learning_rate: 8.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.6951 - loss: 1.7516 - val_accuracy: 0.6545 - val_loss: 1.7840 - learning_rate: 8.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.7129 - loss: 1.6889 - val_accuracy: 0.6626 - val_loss: 1.7095 - learning_rate: 8.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.7491 - loss: 1.6214 - val_accuracy: 0.6626 - val_loss: 1.7374 - learning_rate: 8.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.7504 - loss: 1.6251 - val_accuracy: 0.6667 - val_loss: 1.6922 - learning_rate: 8.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.7727 - loss: 1.5680 - val_accuracy: 0.6870 - val_loss: 1.6964 - learning_rate: 8.0000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.7566 - loss: 1.5770 - val_accuracy: 0.7195 - val_loss: 1.6373 - learning_rate: 8.0000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.7753 - loss: 1.5331 - val_accuracy: 0.6911 - val_loss: 1.6393 - learning_rate: 8.0000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.7675 - loss: 1.5288 - val_accuracy: 0.7358 - val_loss: 1.6189 - learning_rate: 8.0000e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.7987 - loss: 1.4505 - val_accuracy: 0.6789 - val_loss: 1.6654 - learning_rate: 8.0000e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.7963 - loss: 1.4786 - val_accuracy: 0.7276 - val_loss: 1.6065 - learning_rate: 8.0000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.8015 - loss: 1.4200 - val_accuracy: 0.6911 - val_loss: 1.6533 - learning_rate: 8.0000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.8234 - loss: 1.3957 - val_accuracy: 0.7195 - val_loss: 1.6082 - learning_rate: 8.0000e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.8130 - loss: 1.4572 - val_accuracy: 0.6626 - val_loss: 1.6173 - learning_rate: 8.0000e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8253 - loss: 1.4205 - val_accuracy: 0.7276 - val_loss: 1.6097 - learning_rate: 8.0000e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m30/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8318 - loss: 1.3824\n",
            "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00039999998989515007.\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8322 - loss: 1.3803 - val_accuracy: 0.6585 - val_loss: 1.7295 - learning_rate: 8.0000e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.8317 - loss: 1.3635 - val_accuracy: 0.7317 - val_loss: 1.5703 - learning_rate: 4.0000e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.8614 - loss: 1.2938 - val_accuracy: 0.7520 - val_loss: 1.5189 - learning_rate: 4.0000e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.8934 - loss: 1.2357 - val_accuracy: 0.7683 - val_loss: 1.5160 - learning_rate: 4.0000e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.9084 - loss: 1.1852 - val_accuracy: 0.7724 - val_loss: 1.4818 - learning_rate: 4.0000e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8906 - loss: 1.2450 - val_accuracy: 0.7683 - val_loss: 1.5185 - learning_rate: 4.0000e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.8940 - loss: 1.2243 - val_accuracy: 0.7520 - val_loss: 1.4843 - learning_rate: 4.0000e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.9102 - loss: 1.1820 - val_accuracy: 0.7439 - val_loss: 1.5252 - learning_rate: 4.0000e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.8968 - loss: 1.2118 - val_accuracy: 0.7846 - val_loss: 1.5019 - learning_rate: 4.0000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9167 - loss: 1.1823 - val_accuracy: 0.7520 - val_loss: 1.4810 - learning_rate: 4.0000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8914 - loss: 1.1918 - val_accuracy: 0.8130 - val_loss: 1.4462 - learning_rate: 4.0000e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9050 - loss: 1.1914 - val_accuracy: 0.7602 - val_loss: 1.4658 - learning_rate: 4.0000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9078 - loss: 1.1772 - val_accuracy: 0.7764 - val_loss: 1.4405 - learning_rate: 4.0000e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9037 - loss: 1.1803 - val_accuracy: 0.7805 - val_loss: 1.4447 - learning_rate: 4.0000e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9451 - loss: 1.0939 - val_accuracy: 0.7520 - val_loss: 1.4704 - learning_rate: 4.0000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9182 - loss: 1.1580 - val_accuracy: 0.7805 - val_loss: 1.4488 - learning_rate: 4.0000e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9099 - loss: 1.1889 - val_accuracy: 0.7683 - val_loss: 1.4719 - learning_rate: 4.0000e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9058 - loss: 1.1805\n",
            "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.00019999999494757503.\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9061 - loss: 1.1797 - val_accuracy: 0.7520 - val_loss: 1.4886 - learning_rate: 4.0000e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.9241 - loss: 1.1176 - val_accuracy: 0.7724 - val_loss: 1.4427 - learning_rate: 2.0000e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.9266 - loss: 1.1062 - val_accuracy: 0.7724 - val_loss: 1.4731 - learning_rate: 2.0000e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.9600 - loss: 1.0763 - val_accuracy: 0.7561 - val_loss: 1.4462 - learning_rate: 2.0000e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9346 - loss: 1.1349 - val_accuracy: 0.7927 - val_loss: 1.4344 - learning_rate: 2.0000e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9506 - loss: 1.0980 - val_accuracy: 0.7764 - val_loss: 1.4379 - learning_rate: 2.0000e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9546 - loss: 1.0597 - val_accuracy: 0.7886 - val_loss: 1.4313 - learning_rate: 2.0000e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9578 - loss: 1.0433 - val_accuracy: 0.7683 - val_loss: 1.4703 - learning_rate: 2.0000e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9203 - loss: 1.1473 - val_accuracy: 0.7683 - val_loss: 1.4607 - learning_rate: 2.0000e-04\n",
            "Epoch 57/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9572 - loss: 1.0522 - val_accuracy: 0.7967 - val_loss: 1.4555 - learning_rate: 2.0000e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.9461 - loss: 1.0835 - val_accuracy: 0.7724 - val_loss: 1.4475 - learning_rate: 2.0000e-04\n",
            "Epoch 59/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.9257 - loss: 1.1021 - val_accuracy: 0.7967 - val_loss: 1.4233 - learning_rate: 2.0000e-04\n",
            "Epoch 60/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.9539 - loss: 1.0498 - val_accuracy: 0.7967 - val_loss: 1.4202 - learning_rate: 2.0000e-04\n",
            "Epoch 61/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.9495 - loss: 1.0905 - val_accuracy: 0.7805 - val_loss: 1.4542 - learning_rate: 2.0000e-04\n",
            "Epoch 62/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.9560 - loss: 1.0427 - val_accuracy: 0.7927 - val_loss: 1.4438 - learning_rate: 2.0000e-04\n",
            "Epoch 63/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9318 - loss: 1.1137 - val_accuracy: 0.8049 - val_loss: 1.4200 - learning_rate: 2.0000e-04\n",
            "Epoch 64/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9461 - loss: 1.0953 - val_accuracy: 0.7805 - val_loss: 1.4651 - learning_rate: 2.0000e-04\n",
            "Epoch 65/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9707 - loss: 1.0520 - val_accuracy: 0.7886 - val_loss: 1.4521 - learning_rate: 2.0000e-04\n",
            "Epoch 66/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9494 - loss: 1.0888 - val_accuracy: 0.7927 - val_loss: 1.4251 - learning_rate: 2.0000e-04\n",
            "Epoch 67/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9753 - loss: 1.0309 - val_accuracy: 0.8008 - val_loss: 1.3992 - learning_rate: 2.0000e-04\n",
            "Epoch 68/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9563 - loss: 1.0504 - val_accuracy: 0.7805 - val_loss: 1.4275 - learning_rate: 2.0000e-04\n",
            "Epoch 69/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9602 - loss: 1.0380 - val_accuracy: 0.8008 - val_loss: 1.4321 - learning_rate: 2.0000e-04\n",
            "Epoch 70/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.9422 - loss: 1.0733 - val_accuracy: 0.7764 - val_loss: 1.4371 - learning_rate: 2.0000e-04\n",
            "Epoch 71/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.9573 - loss: 1.0406 - val_accuracy: 0.7886 - val_loss: 1.4480 - learning_rate: 2.0000e-04\n",
            "Epoch 72/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9668 - loss: 1.0465\n",
            "Epoch 72: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-05.\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.9666 - loss: 1.0467 - val_accuracy: 0.7846 - val_loss: 1.4190 - learning_rate: 2.0000e-04\n",
            "Epoch 73/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9551 - loss: 1.0586 - val_accuracy: 0.7886 - val_loss: 1.4139 - learning_rate: 1.0000e-04\n",
            "Epoch 74/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9608 - loss: 1.0407 - val_accuracy: 0.7967 - val_loss: 1.4040 - learning_rate: 1.0000e-04\n",
            "Epoch 75/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9543 - loss: 1.0626 - val_accuracy: 0.7886 - val_loss: 1.4203 - learning_rate: 1.0000e-04\n",
            "Epoch 76/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9670 - loss: 1.0131 - val_accuracy: 0.8049 - val_loss: 1.4038 - learning_rate: 1.0000e-04\n",
            "Epoch 77/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9601 - loss: 1.0405\n",
            "Epoch 77: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9602 - loss: 1.0401 - val_accuracy: 0.8089 - val_loss: 1.4011 - learning_rate: 1.0000e-04\n",
            "Epoch 78/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9627 - loss: 1.0296 - val_accuracy: 0.8089 - val_loss: 1.4043 - learning_rate: 5.0000e-05\n",
            "Epoch 79/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9595 - loss: 1.0331 - val_accuracy: 0.8008 - val_loss: 1.4044 - learning_rate: 5.0000e-05\n",
            "Epoch 80/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.9632 - loss: 1.0190 - val_accuracy: 0.8171 - val_loss: 1.3981 - learning_rate: 5.0000e-05\n",
            "Epoch 81/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.9487 - loss: 1.0214 - val_accuracy: 0.8171 - val_loss: 1.4010 - learning_rate: 5.0000e-05\n",
            "Epoch 82/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.9617 - loss: 1.0549 - val_accuracy: 0.8008 - val_loss: 1.4055 - learning_rate: 5.0000e-05\n",
            "Epoch 83/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9687 - loss: 1.0115 - val_accuracy: 0.8049 - val_loss: 1.3978 - learning_rate: 5.0000e-05\n",
            "Epoch 84/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9733 - loss: 1.0101 - val_accuracy: 0.8130 - val_loss: 1.3941 - learning_rate: 5.0000e-05\n",
            "Epoch 85/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9739 - loss: 0.9857 - val_accuracy: 0.8089 - val_loss: 1.4016 - learning_rate: 5.0000e-05\n",
            "Epoch 86/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9626 - loss: 1.0226 - val_accuracy: 0.8171 - val_loss: 1.4003 - learning_rate: 5.0000e-05\n",
            "Epoch 87/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9755 - loss: 1.0181 - val_accuracy: 0.8171 - val_loss: 1.3937 - learning_rate: 5.0000e-05\n",
            "Epoch 88/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9601 - loss: 1.0091 - val_accuracy: 0.8171 - val_loss: 1.3989 - learning_rate: 5.0000e-05\n",
            "Epoch 89/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.9677 - loss: 1.0061 - val_accuracy: 0.8089 - val_loss: 1.3979 - learning_rate: 5.0000e-05\n",
            "Epoch 90/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.9739 - loss: 1.0274 - val_accuracy: 0.8089 - val_loss: 1.3929 - learning_rate: 5.0000e-05\n",
            "Epoch 91/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.9692 - loss: 1.0220 - val_accuracy: 0.8049 - val_loss: 1.3922 - learning_rate: 5.0000e-05\n",
            "Epoch 92/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.9562 - loss: 1.0206 - val_accuracy: 0.8130 - val_loss: 1.4001 - learning_rate: 5.0000e-05\n",
            "Epoch 93/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.9639 - loss: 1.0135 - val_accuracy: 0.8130 - val_loss: 1.3944 - learning_rate: 5.0000e-05\n",
            "Epoch 94/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9682 - loss: 1.0037 - val_accuracy: 0.8171 - val_loss: 1.3916 - learning_rate: 5.0000e-05\n",
            "Epoch 95/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9668 - loss: 1.0305 - val_accuracy: 0.8211 - val_loss: 1.3938 - learning_rate: 5.0000e-05\n",
            "Epoch 96/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9806 - loss: 0.9992 - val_accuracy: 0.8171 - val_loss: 1.3962 - learning_rate: 5.0000e-05\n",
            "Epoch 97/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9728 - loss: 0.9938 - val_accuracy: 0.8211 - val_loss: 1.3886 - learning_rate: 5.0000e-05\n",
            "Epoch 98/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9679 - loss: 1.0138 - val_accuracy: 0.8211 - val_loss: 1.4017 - learning_rate: 5.0000e-05\n",
            "Epoch 99/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9718 - loss: 1.0066 - val_accuracy: 0.8171 - val_loss: 1.3972 - learning_rate: 5.0000e-05\n",
            "Epoch 100/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9583 - loss: 1.0140 - val_accuracy: 0.8171 - val_loss: 1.3868 - learning_rate: 5.0000e-05\n",
            "Restoring model weights from the end of the best epoch: 100.\n",
            "  âœ… Transformer_v1 Val Acc: 81.71%\n",
            "\n",
            "============================================================\n",
            "ğŸ—ï¸ ResNet1D_v1 í•™ìŠµ ì¤‘... (LR: 0.001)\n",
            "============================================================\n",
            "Epoch 1/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 410ms/step - accuracy: 0.0294 - loss: 4.3544 - val_accuracy: 0.0163 - val_loss: 4.1336 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.0624 - loss: 3.9817 - val_accuracy: 0.0772 - val_loss: 3.8512 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.1230 - loss: 3.7920 - val_accuracy: 0.1138 - val_loss: 3.5360 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.1672 - loss: 3.4963 - val_accuracy: 0.2439 - val_loss: 3.1793 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.1476 - loss: 3.4671 - val_accuracy: 0.1992 - val_loss: 3.1494 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.1983 - loss: 3.3306 - val_accuracy: 0.2480 - val_loss: 3.0181 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.2473 - loss: 3.0588 - val_accuracy: 0.3496 - val_loss: 2.7145 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.2458 - loss: 3.0194 - val_accuracy: 0.2886 - val_loss: 2.7392 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.3118 - loss: 2.8382 - val_accuracy: 0.3902 - val_loss: 2.6114 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.3351 - loss: 2.7332 - val_accuracy: 0.4715 - val_loss: 2.4134 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.3632 - loss: 2.6577 - val_accuracy: 0.4837 - val_loss: 2.3552 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.3677 - loss: 2.5849 - val_accuracy: 0.4634 - val_loss: 2.3688 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.4124 - loss: 2.4927 - val_accuracy: 0.4512 - val_loss: 2.3369 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.4650 - loss: 2.4335 - val_accuracy: 0.5000 - val_loss: 2.1991 - learning_rate: 0.0010\n",
            "Epoch 15/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.4219 - loss: 2.4662 - val_accuracy: 0.5163 - val_loss: 2.2034 - learning_rate: 0.0010\n",
            "Epoch 16/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.4621 - loss: 2.3924 - val_accuracy: 0.5081 - val_loss: 2.3111 - learning_rate: 0.0010\n",
            "Epoch 17/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.4682 - loss: 2.3253 - val_accuracy: 0.5610 - val_loss: 2.1662 - learning_rate: 0.0010\n",
            "Epoch 18/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.5120 - loss: 2.2277 - val_accuracy: 0.5569 - val_loss: 2.1752 - learning_rate: 0.0010\n",
            "Epoch 19/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.5710 - loss: 2.1365 - val_accuracy: 0.5528 - val_loss: 2.0819 - learning_rate: 0.0010\n",
            "Epoch 20/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.5336 - loss: 2.1786 - val_accuracy: 0.5691 - val_loss: 2.0910 - learning_rate: 0.0010\n",
            "Epoch 21/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.5799 - loss: 2.0589 - val_accuracy: 0.6057 - val_loss: 2.0159 - learning_rate: 0.0010\n",
            "Epoch 22/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.5825 - loss: 2.0618 - val_accuracy: 0.6179 - val_loss: 2.0184 - learning_rate: 0.0010\n",
            "Epoch 23/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.5824 - loss: 2.0531 - val_accuracy: 0.6260 - val_loss: 1.9172 - learning_rate: 0.0010\n",
            "Epoch 24/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.6034 - loss: 2.0108 - val_accuracy: 0.6220 - val_loss: 1.9278 - learning_rate: 0.0010\n",
            "Epoch 25/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.5933 - loss: 2.0385 - val_accuracy: 0.6301 - val_loss: 1.9066 - learning_rate: 0.0010\n",
            "Epoch 26/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.6048 - loss: 2.0131 - val_accuracy: 0.6423 - val_loss: 1.9344 - learning_rate: 0.0010\n",
            "Epoch 27/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.6211 - loss: 1.8918 - val_accuracy: 0.6341 - val_loss: 1.8761 - learning_rate: 0.0010\n",
            "Epoch 28/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.6595 - loss: 1.8255 - val_accuracy: 0.6667 - val_loss: 1.8341 - learning_rate: 0.0010\n",
            "Epoch 29/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.6698 - loss: 1.8696 - val_accuracy: 0.6789 - val_loss: 1.8487 - learning_rate: 0.0010\n",
            "Epoch 30/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.6787 - loss: 1.8531 - val_accuracy: 0.6463 - val_loss: 1.8963 - learning_rate: 0.0010\n",
            "Epoch 31/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.7032 - loss: 1.7847 - val_accuracy: 0.6220 - val_loss: 1.8433 - learning_rate: 0.0010\n",
            "Epoch 32/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.6516 - loss: 1.8072 - val_accuracy: 0.6138 - val_loss: 1.9360 - learning_rate: 0.0010\n",
            "Epoch 33/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.6731 - loss: 1.8260 - val_accuracy: 0.7114 - val_loss: 1.7463 - learning_rate: 0.0010\n",
            "Epoch 34/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.6818 - loss: 1.8068 - val_accuracy: 0.6829 - val_loss: 1.7958 - learning_rate: 0.0010\n",
            "Epoch 35/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.7083 - loss: 1.7370 - val_accuracy: 0.6707 - val_loss: 1.8355 - learning_rate: 0.0010\n",
            "Epoch 36/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.6873 - loss: 1.7970 - val_accuracy: 0.6829 - val_loss: 1.8589 - learning_rate: 0.0010\n",
            "Epoch 37/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.7318 - loss: 1.6812 - val_accuracy: 0.6667 - val_loss: 1.7902 - learning_rate: 0.0010\n",
            "Epoch 38/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7546 - loss: 1.6483\n",
            "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.7537 - loss: 1.6505 - val_accuracy: 0.6667 - val_loss: 1.9349 - learning_rate: 0.0010\n",
            "Epoch 39/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.7393 - loss: 1.6633 - val_accuracy: 0.7480 - val_loss: 1.6587 - learning_rate: 5.0000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.7696 - loss: 1.6182 - val_accuracy: 0.7358 - val_loss: 1.6509 - learning_rate: 5.0000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.7802 - loss: 1.6462 - val_accuracy: 0.7520 - val_loss: 1.6076 - learning_rate: 5.0000e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.7939 - loss: 1.5447 - val_accuracy: 0.7154 - val_loss: 1.6416 - learning_rate: 5.0000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.7753 - loss: 1.5894 - val_accuracy: 0.7398 - val_loss: 1.5952 - learning_rate: 5.0000e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.8158 - loss: 1.5333 - val_accuracy: 0.7276 - val_loss: 1.5970 - learning_rate: 5.0000e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.7657 - loss: 1.5545 - val_accuracy: 0.7358 - val_loss: 1.5932 - learning_rate: 5.0000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.7939 - loss: 1.5402 - val_accuracy: 0.7154 - val_loss: 1.6051 - learning_rate: 5.0000e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.8021 - loss: 1.5328 - val_accuracy: 0.7114 - val_loss: 1.6094 - learning_rate: 5.0000e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8035 - loss: 1.5167 - val_accuracy: 0.7602 - val_loss: 1.5283 - learning_rate: 5.0000e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.7920 - loss: 1.5241 - val_accuracy: 0.7195 - val_loss: 1.5751 - learning_rate: 5.0000e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.8023 - loss: 1.5244 - val_accuracy: 0.7236 - val_loss: 1.5962 - learning_rate: 5.0000e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.8150 - loss: 1.4572 - val_accuracy: 0.7398 - val_loss: 1.5754 - learning_rate: 5.0000e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.7988 - loss: 1.5089 - val_accuracy: 0.7317 - val_loss: 1.5746 - learning_rate: 5.0000e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m29/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7945 - loss: 1.4775\n",
            "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.7953 - loss: 1.4758 - val_accuracy: 0.7154 - val_loss: 1.5836 - learning_rate: 5.0000e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.8338 - loss: 1.4123 - val_accuracy: 0.7236 - val_loss: 1.5591 - learning_rate: 2.5000e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8473 - loss: 1.4045 - val_accuracy: 0.7480 - val_loss: 1.5449 - learning_rate: 2.5000e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.8648 - loss: 1.3649 - val_accuracy: 0.7398 - val_loss: 1.5375 - learning_rate: 2.5000e-04\n",
            "Epoch 57/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.8254 - loss: 1.3992 - val_accuracy: 0.7358 - val_loss: 1.5292 - learning_rate: 2.5000e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8448 - loss: 1.4179\n",
            "Epoch 58: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.8447 - loss: 1.4174 - val_accuracy: 0.7480 - val_loss: 1.5550 - learning_rate: 2.5000e-04\n",
            "Epoch 59/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.8439 - loss: 1.4159 - val_accuracy: 0.7439 - val_loss: 1.5355 - learning_rate: 1.2500e-04\n",
            "Epoch 60/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8439 - loss: 1.4017 - val_accuracy: 0.7520 - val_loss: 1.5215 - learning_rate: 1.2500e-04\n",
            "Epoch 61/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8632 - loss: 1.3790 - val_accuracy: 0.7480 - val_loss: 1.5052 - learning_rate: 1.2500e-04\n",
            "Epoch 62/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.8431 - loss: 1.3930 - val_accuracy: 0.7439 - val_loss: 1.5134 - learning_rate: 1.2500e-04\n",
            "Epoch 63/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8576 - loss: 1.3603 - val_accuracy: 0.7480 - val_loss: 1.5030 - learning_rate: 1.2500e-04\n",
            "Epoch 64/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.8384 - loss: 1.4000 - val_accuracy: 0.7561 - val_loss: 1.4978 - learning_rate: 1.2500e-04\n",
            "Epoch 65/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.8310 - loss: 1.4157 - val_accuracy: 0.7602 - val_loss: 1.4978 - learning_rate: 1.2500e-04\n",
            "Epoch 66/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8577 - loss: 1.3329 - val_accuracy: 0.7683 - val_loss: 1.5005 - learning_rate: 1.2500e-04\n",
            "Epoch 67/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.8755 - loss: 1.3702 - val_accuracy: 0.7683 - val_loss: 1.4983 - learning_rate: 1.2500e-04\n",
            "Epoch 68/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.8585 - loss: 1.3515 - val_accuracy: 0.7642 - val_loss: 1.4887 - learning_rate: 1.2500e-04\n",
            "Epoch 69/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.8634 - loss: 1.3400 - val_accuracy: 0.7683 - val_loss: 1.4953 - learning_rate: 1.2500e-04\n",
            "Epoch 70/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.8467 - loss: 1.3822 - val_accuracy: 0.7561 - val_loss: 1.4857 - learning_rate: 1.2500e-04\n",
            "Epoch 71/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.8672 - loss: 1.3420 - val_accuracy: 0.7764 - val_loss: 1.4961 - learning_rate: 1.2500e-04\n",
            "Epoch 72/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8411 - loss: 1.4246 - val_accuracy: 0.7724 - val_loss: 1.5036 - learning_rate: 1.2500e-04\n",
            "Epoch 73/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.8638 - loss: 1.3673 - val_accuracy: 0.7846 - val_loss: 1.4911 - learning_rate: 1.2500e-04\n",
            "Epoch 74/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.8682 - loss: 1.3491 - val_accuracy: 0.7602 - val_loss: 1.5037 - learning_rate: 1.2500e-04\n",
            "Epoch 75/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8899 - loss: 1.2991\n",
            "Epoch 75: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.8896 - loss: 1.2997 - val_accuracy: 0.7642 - val_loss: 1.4912 - learning_rate: 1.2500e-04\n",
            "Epoch 76/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8612 - loss: 1.3649 - val_accuracy: 0.7642 - val_loss: 1.4911 - learning_rate: 6.2500e-05\n",
            "Epoch 77/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8601 - loss: 1.3608 - val_accuracy: 0.7805 - val_loss: 1.4842 - learning_rate: 6.2500e-05\n",
            "Epoch 78/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.8862 - loss: 1.3340 - val_accuracy: 0.7602 - val_loss: 1.4784 - learning_rate: 6.2500e-05\n",
            "Epoch 79/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.8725 - loss: 1.2953 - val_accuracy: 0.7724 - val_loss: 1.4781 - learning_rate: 6.2500e-05\n",
            "Epoch 80/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.8698 - loss: 1.3122 - val_accuracy: 0.7683 - val_loss: 1.4847 - learning_rate: 6.2500e-05\n",
            "Epoch 81/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8954 - loss: 1.3091 - val_accuracy: 0.7764 - val_loss: 1.4771 - learning_rate: 6.2500e-05\n",
            "Epoch 82/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.8582 - loss: 1.3366 - val_accuracy: 0.7724 - val_loss: 1.4882 - learning_rate: 6.2500e-05\n",
            "Epoch 83/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.8680 - loss: 1.3091 - val_accuracy: 0.7846 - val_loss: 1.4942 - learning_rate: 6.2500e-05\n",
            "Epoch 84/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.8731 - loss: 1.3590 - val_accuracy: 0.7724 - val_loss: 1.4891 - learning_rate: 6.2500e-05\n",
            "Epoch 85/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8666 - loss: 1.3372 - val_accuracy: 0.7683 - val_loss: 1.4871 - learning_rate: 6.2500e-05\n",
            "Epoch 86/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8589 - loss: 1.3524\n",
            "Epoch 86: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8593 - loss: 1.3517 - val_accuracy: 0.7642 - val_loss: 1.4793 - learning_rate: 6.2500e-05\n",
            "Epoch 87/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8773 - loss: 1.3038 - val_accuracy: 0.7764 - val_loss: 1.4770 - learning_rate: 3.1250e-05\n",
            "Epoch 88/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8970 - loss: 1.2584 - val_accuracy: 0.7683 - val_loss: 1.4769 - learning_rate: 3.1250e-05\n",
            "Epoch 89/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.8925 - loss: 1.3120 - val_accuracy: 0.7683 - val_loss: 1.4775 - learning_rate: 3.1250e-05\n",
            "Epoch 90/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.8744 - loss: 1.3245 - val_accuracy: 0.7764 - val_loss: 1.4784 - learning_rate: 3.1250e-05\n",
            "Epoch 91/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.8577 - loss: 1.3593 - val_accuracy: 0.7764 - val_loss: 1.4770 - learning_rate: 3.1250e-05\n",
            "Epoch 92/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8871 - loss: 1.3143 - val_accuracy: 0.7805 - val_loss: 1.4729 - learning_rate: 3.1250e-05\n",
            "Epoch 93/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8824 - loss: 1.3095 - val_accuracy: 0.7805 - val_loss: 1.4701 - learning_rate: 3.1250e-05\n",
            "Epoch 94/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.8714 - loss: 1.3301 - val_accuracy: 0.7846 - val_loss: 1.4709 - learning_rate: 3.1250e-05\n",
            "Epoch 95/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8797 - loss: 1.3087 - val_accuracy: 0.7764 - val_loss: 1.4689 - learning_rate: 3.1250e-05\n",
            "Epoch 96/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.8646 - loss: 1.3271 - val_accuracy: 0.7764 - val_loss: 1.4699 - learning_rate: 3.1250e-05\n",
            "Epoch 97/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8751 - loss: 1.3426 - val_accuracy: 0.7602 - val_loss: 1.4641 - learning_rate: 3.1250e-05\n",
            "Epoch 98/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.8819 - loss: 1.3014 - val_accuracy: 0.7642 - val_loss: 1.4670 - learning_rate: 3.1250e-05\n",
            "Epoch 99/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8580 - loss: 1.3533 - val_accuracy: 0.7642 - val_loss: 1.4656 - learning_rate: 3.1250e-05\n",
            "Epoch 100/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.8680 - loss: 1.3524 - val_accuracy: 0.7805 - val_loss: 1.4728 - learning_rate: 3.1250e-05\n",
            "Restoring model weights from the end of the best epoch: 97.\n",
            "  âœ… ResNet1D_v1 Val Acc: 76.02%\n",
            "\n",
            "============================================================\n",
            "ğŸ—ï¸ ResNet1D_v2 í•™ìŠµ ì¤‘... (LR: 0.0005)\n",
            "============================================================\n",
            "Epoch 1/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 389ms/step - accuracy: 0.0109 - loss: 4.3289 - val_accuracy: 0.0285 - val_loss: 4.1384 - learning_rate: 5.0000e-04\n",
            "Epoch 2/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.0592 - loss: 3.9986 - val_accuracy: 0.1260 - val_loss: 3.8920 - learning_rate: 5.0000e-04\n",
            "Epoch 3/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.0950 - loss: 3.7800 - val_accuracy: 0.1870 - val_loss: 3.6022 - learning_rate: 5.0000e-04\n",
            "Epoch 4/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.1657 - loss: 3.5603 - val_accuracy: 0.2236 - val_loss: 3.3748 - learning_rate: 5.0000e-04\n",
            "Epoch 5/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.1982 - loss: 3.4225 - val_accuracy: 0.3171 - val_loss: 3.1726 - learning_rate: 5.0000e-04\n",
            "Epoch 6/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.2409 - loss: 3.1875 - val_accuracy: 0.3577 - val_loss: 2.9124 - learning_rate: 5.0000e-04\n",
            "Epoch 7/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.2652 - loss: 3.1190 - val_accuracy: 0.3455 - val_loss: 2.7925 - learning_rate: 5.0000e-04\n",
            "Epoch 8/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.3118 - loss: 2.9104 - val_accuracy: 0.4065 - val_loss: 2.6391 - learning_rate: 5.0000e-04\n",
            "Epoch 9/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.3335 - loss: 2.8275 - val_accuracy: 0.4797 - val_loss: 2.4790 - learning_rate: 5.0000e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.3519 - loss: 2.7756 - val_accuracy: 0.4350 - val_loss: 2.4464 - learning_rate: 5.0000e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.4108 - loss: 2.5924 - val_accuracy: 0.5366 - val_loss: 2.2556 - learning_rate: 5.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.4059 - loss: 2.5679 - val_accuracy: 0.5244 - val_loss: 2.2540 - learning_rate: 5.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.4282 - loss: 2.4814 - val_accuracy: 0.5447 - val_loss: 2.1862 - learning_rate: 5.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.4628 - loss: 2.4455 - val_accuracy: 0.5366 - val_loss: 2.1651 - learning_rate: 5.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.4914 - loss: 2.3641 - val_accuracy: 0.5569 - val_loss: 2.1486 - learning_rate: 5.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.5097 - loss: 2.3466 - val_accuracy: 0.5894 - val_loss: 2.0676 - learning_rate: 5.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.5107 - loss: 2.2351 - val_accuracy: 0.5691 - val_loss: 2.0694 - learning_rate: 5.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.5246 - loss: 2.2145 - val_accuracy: 0.6016 - val_loss: 2.0505 - learning_rate: 5.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.5282 - loss: 2.2067 - val_accuracy: 0.5732 - val_loss: 2.0017 - learning_rate: 5.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.5433 - loss: 2.1523 - val_accuracy: 0.6016 - val_loss: 2.0057 - learning_rate: 5.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.5849 - loss: 2.1052 - val_accuracy: 0.6138 - val_loss: 2.0229 - learning_rate: 5.0000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.5669 - loss: 2.1021 - val_accuracy: 0.6179 - val_loss: 1.9375 - learning_rate: 5.0000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.6234 - loss: 2.0364 - val_accuracy: 0.6016 - val_loss: 1.9519 - learning_rate: 5.0000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.6130 - loss: 2.0218 - val_accuracy: 0.6545 - val_loss: 1.8831 - learning_rate: 5.0000e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.6351 - loss: 1.9630 - val_accuracy: 0.6463 - val_loss: 1.8413 - learning_rate: 5.0000e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.6295 - loss: 1.9269 - val_accuracy: 0.6382 - val_loss: 1.9170 - learning_rate: 5.0000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.6365 - loss: 1.9743 - val_accuracy: 0.6585 - val_loss: 1.9031 - learning_rate: 5.0000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.6713 - loss: 1.8999 - val_accuracy: 0.6260 - val_loss: 1.8989 - learning_rate: 5.0000e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.6697 - loss: 1.8621 - val_accuracy: 0.6545 - val_loss: 1.8745 - learning_rate: 5.0000e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m30/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6492 - loss: 1.8851\n",
            "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.6488 - loss: 1.8863 - val_accuracy: 0.6463 - val_loss: 1.8562 - learning_rate: 5.0000e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.6989 - loss: 1.7746 - val_accuracy: 0.7154 - val_loss: 1.7320 - learning_rate: 2.5000e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.7037 - loss: 1.7289 - val_accuracy: 0.6911 - val_loss: 1.7630 - learning_rate: 2.5000e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.7180 - loss: 1.7453 - val_accuracy: 0.6992 - val_loss: 1.7553 - learning_rate: 2.5000e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.7433 - loss: 1.7217 - val_accuracy: 0.7154 - val_loss: 1.7045 - learning_rate: 2.5000e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.7096 - loss: 1.7460 - val_accuracy: 0.6911 - val_loss: 1.7661 - learning_rate: 2.5000e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.7391 - loss: 1.6678 - val_accuracy: 0.7114 - val_loss: 1.7195 - learning_rate: 2.5000e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.7433 - loss: 1.6426 - val_accuracy: 0.7561 - val_loss: 1.6822 - learning_rate: 2.5000e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.7257 - loss: 1.6743 - val_accuracy: 0.6829 - val_loss: 1.7086 - learning_rate: 2.5000e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.7157 - loss: 1.7569 - val_accuracy: 0.7033 - val_loss: 1.7177 - learning_rate: 2.5000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.7079 - loss: 1.7951 - val_accuracy: 0.7195 - val_loss: 1.7174 - learning_rate: 2.5000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.7391 - loss: 1.6743 - val_accuracy: 0.6951 - val_loss: 1.7353 - learning_rate: 2.5000e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7672 - loss: 1.6172\n",
            "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.7665 - loss: 1.6181 - val_accuracy: 0.7073 - val_loss: 1.7211 - learning_rate: 2.5000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.7591 - loss: 1.6784 - val_accuracy: 0.7276 - val_loss: 1.6748 - learning_rate: 1.2500e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.7904 - loss: 1.5794 - val_accuracy: 0.7195 - val_loss: 1.6514 - learning_rate: 1.2500e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.8183 - loss: 1.5415 - val_accuracy: 0.7480 - val_loss: 1.6483 - learning_rate: 1.2500e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.7924 - loss: 1.5533 - val_accuracy: 0.7358 - val_loss: 1.6482 - learning_rate: 1.2500e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.7485 - loss: 1.6164 - val_accuracy: 0.7236 - val_loss: 1.6482 - learning_rate: 1.2500e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.7891 - loss: 1.5953 - val_accuracy: 0.7398 - val_loss: 1.6296 - learning_rate: 1.2500e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.7474 - loss: 1.6928 - val_accuracy: 0.7398 - val_loss: 1.6385 - learning_rate: 1.2500e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.7704 - loss: 1.5458 - val_accuracy: 0.7358 - val_loss: 1.6426 - learning_rate: 1.2500e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.8073 - loss: 1.5397 - val_accuracy: 0.7154 - val_loss: 1.6429 - learning_rate: 1.2500e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.7629 - loss: 1.5971 - val_accuracy: 0.7398 - val_loss: 1.6313 - learning_rate: 1.2500e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m30/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7894 - loss: 1.5134\n",
            "Epoch 53: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.7903 - loss: 1.5142 - val_accuracy: 0.7236 - val_loss: 1.6533 - learning_rate: 1.2500e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.8021 - loss: 1.4990 - val_accuracy: 0.7398 - val_loss: 1.6170 - learning_rate: 6.2500e-05\n",
            "Epoch 55/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8226 - loss: 1.5163 - val_accuracy: 0.7398 - val_loss: 1.6167 - learning_rate: 6.2500e-05\n",
            "Epoch 56/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8039 - loss: 1.4991 - val_accuracy: 0.7276 - val_loss: 1.6062 - learning_rate: 6.2500e-05\n",
            "Epoch 57/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.7923 - loss: 1.5028 - val_accuracy: 0.7358 - val_loss: 1.6206 - learning_rate: 6.2500e-05\n",
            "Epoch 58/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.8105 - loss: 1.5144 - val_accuracy: 0.7236 - val_loss: 1.6108 - learning_rate: 6.2500e-05\n",
            "Epoch 59/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.7821 - loss: 1.5279 - val_accuracy: 0.7480 - val_loss: 1.6065 - learning_rate: 6.2500e-05\n",
            "Epoch 60/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8046 - loss: 1.4796 - val_accuracy: 0.7398 - val_loss: 1.5997 - learning_rate: 6.2500e-05\n",
            "Epoch 61/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.7914 - loss: 1.5157 - val_accuracy: 0.7398 - val_loss: 1.6104 - learning_rate: 6.2500e-05\n",
            "Epoch 62/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8306 - loss: 1.4769 - val_accuracy: 0.7439 - val_loss: 1.6070 - learning_rate: 6.2500e-05\n",
            "Epoch 63/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.8051 - loss: 1.5176 - val_accuracy: 0.7520 - val_loss: 1.6145 - learning_rate: 6.2500e-05\n",
            "Epoch 64/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.8206 - loss: 1.4747 - val_accuracy: 0.7358 - val_loss: 1.5935 - learning_rate: 6.2500e-05\n",
            "Epoch 65/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.7821 - loss: 1.5628 - val_accuracy: 0.7439 - val_loss: 1.5993 - learning_rate: 6.2500e-05\n",
            "Epoch 66/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8233 - loss: 1.4544 - val_accuracy: 0.7602 - val_loss: 1.5842 - learning_rate: 6.2500e-05\n",
            "Epoch 67/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8055 - loss: 1.4936 - val_accuracy: 0.7561 - val_loss: 1.5880 - learning_rate: 6.2500e-05\n",
            "Epoch 68/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.7890 - loss: 1.4956 - val_accuracy: 0.7561 - val_loss: 1.5941 - learning_rate: 6.2500e-05\n",
            "Epoch 69/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8047 - loss: 1.5093 - val_accuracy: 0.7520 - val_loss: 1.5934 - learning_rate: 6.2500e-05\n",
            "Epoch 70/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.8007 - loss: 1.4945 - val_accuracy: 0.7520 - val_loss: 1.5900 - learning_rate: 6.2500e-05\n",
            "Epoch 71/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8184 - loss: 1.4534\n",
            "Epoch 71: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.8178 - loss: 1.4545 - val_accuracy: 0.7439 - val_loss: 1.5992 - learning_rate: 6.2500e-05\n",
            "Epoch 72/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.8209 - loss: 1.5179 - val_accuracy: 0.7561 - val_loss: 1.5976 - learning_rate: 3.1250e-05\n",
            "Epoch 73/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.7813 - loss: 1.5478 - val_accuracy: 0.7561 - val_loss: 1.5926 - learning_rate: 3.1250e-05\n",
            "Epoch 74/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.8264 - loss: 1.4648 - val_accuracy: 0.7642 - val_loss: 1.5873 - learning_rate: 3.1250e-05\n",
            "Epoch 75/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.8133 - loss: 1.4702 - val_accuracy: 0.7602 - val_loss: 1.5810 - learning_rate: 3.1250e-05\n",
            "Epoch 76/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8254 - loss: 1.4769 - val_accuracy: 0.7602 - val_loss: 1.5810 - learning_rate: 3.1250e-05\n",
            "Epoch 77/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.8252 - loss: 1.4708 - val_accuracy: 0.7561 - val_loss: 1.5794 - learning_rate: 3.1250e-05\n",
            "Epoch 78/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8141 - loss: 1.4512 - val_accuracy: 0.7480 - val_loss: 1.5868 - learning_rate: 3.1250e-05\n",
            "Epoch 79/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8340 - loss: 1.4370 - val_accuracy: 0.7520 - val_loss: 1.5835 - learning_rate: 3.1250e-05\n",
            "Epoch 80/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8331 - loss: 1.4579 - val_accuracy: 0.7520 - val_loss: 1.5826 - learning_rate: 3.1250e-05\n",
            "Epoch 81/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.8151 - loss: 1.4648 - val_accuracy: 0.7520 - val_loss: 1.5851 - learning_rate: 3.1250e-05\n",
            "Epoch 82/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8105 - loss: 1.4480\n",
            "Epoch 82: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8107 - loss: 1.4483 - val_accuracy: 0.7480 - val_loss: 1.5889 - learning_rate: 3.1250e-05\n",
            "Epoch 83/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8417 - loss: 1.4332 - val_accuracy: 0.7602 - val_loss: 1.5889 - learning_rate: 1.5625e-05\n",
            "Epoch 84/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.8262 - loss: 1.4593 - val_accuracy: 0.7480 - val_loss: 1.5881 - learning_rate: 1.5625e-05\n",
            "Epoch 85/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.8009 - loss: 1.4826 - val_accuracy: 0.7520 - val_loss: 1.5852 - learning_rate: 1.5625e-05\n",
            "Epoch 86/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.8194 - loss: 1.4778 - val_accuracy: 0.7480 - val_loss: 1.5831 - learning_rate: 1.5625e-05\n",
            "Epoch 87/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8454 - loss: 1.4278\n",
            "Epoch 87: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8450 - loss: 1.4283 - val_accuracy: 0.7561 - val_loss: 1.5842 - learning_rate: 1.5625e-05\n",
            "Epoch 88/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8062 - loss: 1.5348 - val_accuracy: 0.7561 - val_loss: 1.5828 - learning_rate: 7.8125e-06\n",
            "Epoch 89/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8159 - loss: 1.4706 - val_accuracy: 0.7602 - val_loss: 1.5821 - learning_rate: 7.8125e-06\n",
            "Epoch 90/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8203 - loss: 1.4627 - val_accuracy: 0.7642 - val_loss: 1.5797 - learning_rate: 7.8125e-06\n",
            "Epoch 91/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.8520 - loss: 1.3927 - val_accuracy: 0.7642 - val_loss: 1.5792 - learning_rate: 7.8125e-06\n",
            "Epoch 92/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8325 - loss: 1.4409 - val_accuracy: 0.7683 - val_loss: 1.5801 - learning_rate: 7.8125e-06\n",
            "Epoch 93/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8189 - loss: 1.4918 - val_accuracy: 0.7724 - val_loss: 1.5812 - learning_rate: 7.8125e-06\n",
            "Epoch 94/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.8549 - loss: 1.4366 - val_accuracy: 0.7724 - val_loss: 1.5812 - learning_rate: 7.8125e-06\n",
            "Epoch 95/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.8193 - loss: 1.5351 - val_accuracy: 0.7764 - val_loss: 1.5799 - learning_rate: 7.8125e-06\n",
            "Epoch 96/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.8069 - loss: 1.4736 - val_accuracy: 0.7805 - val_loss: 1.5788 - learning_rate: 7.8125e-06\n",
            "Epoch 97/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.8376 - loss: 1.4343 - val_accuracy: 0.7724 - val_loss: 1.5796 - learning_rate: 7.8125e-06\n",
            "Epoch 98/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.8026 - loss: 1.5046 - val_accuracy: 0.7764 - val_loss: 1.5784 - learning_rate: 7.8125e-06\n",
            "Epoch 99/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.8100 - loss: 1.5183 - val_accuracy: 0.7724 - val_loss: 1.5762 - learning_rate: 7.8125e-06\n",
            "Epoch 100/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8297 - loss: 1.4284 - val_accuracy: 0.7724 - val_loss: 1.5771 - learning_rate: 7.8125e-06\n",
            "Restoring model weights from the end of the best epoch: 99.\n",
            "  âœ… ResNet1D_v2 Val Acc: 77.24%\n",
            "\n",
            "\n",
            "============================================================\n",
            "ğŸ“Š ìµœì¢… ì„±ëŠ¥ í‰ê°€ (Validation Set)\n",
            "============================================================\n",
            "ğŸ† [Averaging] Ensemble Accuracy: 84.15%\n",
            "\n",
            "ğŸ”® Mega TTA (ê° ëª¨ë¸ë‹¹ 10ë²ˆ ì¦ê°•)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TTA Models: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:14<00:00,  2.13s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸš€ [Mega TTA] Ensemble Accuracy : 81.71%\n",
            "\n",
            "ğŸ¯ ìŠ¤íƒœí‚¹ ì•™ìƒë¸” í•™ìŠµ\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Stacking Features: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:05<00:00,  1.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ë©”íƒ€ íŠ¹ì§• shape: (983, 469)\n",
            "ğŸ‘‘ [Stacking] Ensemble Accuracy: 85.37%\n",
            "\n",
            "============================================================\n",
            "ğŸ‰ ëª¨ë“  í•™ìŠµ ë° í‰ê°€ ì™„ë£Œ.\n",
            "============================================================\n"
          ]
        }
      ]
    }
  ]
}